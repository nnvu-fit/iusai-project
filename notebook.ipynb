{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "## Outline\n",
    "1. Import Library\n",
    "2. Setup pre-requisites\n",
    "3. Extract dataset to images\n",
    "4. Upload images to Azure data store\n",
    "4. Setting up Azure ML Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: torch in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: azureml-core in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.53.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: requests in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: azure-mgmt-resource<=22.0.0,>=15.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (22.0.0)\n",
      "Requirement already satisfied: pyopenssl<24.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (23.2.0)\n",
      "Requirement already satisfied: contextlib2<22.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (21.6.0)\n",
      "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.61.1)\n",
      "Requirement already satisfied: SecretStorage<4.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.3.3)\n",
      "Requirement already satisfied: azure-mgmt-storage<=21.0.0,>=16.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (21.0.0)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (10.2.0)\n",
      "Requirement already satisfied: pathspec<1.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.11.2)\n",
      "Requirement already satisfied: jmespath<2.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.0.1)\n",
      "Requirement already satisfied: packaging<=23.0,>=20.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (23.0)\n",
      "Requirement already satisfied: azure-core<2.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.29.4)\n",
      "Requirement already satisfied: pkginfo in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.9.6)\n",
      "Requirement already satisfied: PyJWT<3.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.8.0)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.15.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.24.1)\n",
      "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (10.2.3)\n",
      "Requirement already satisfied: backports.tempfile in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.0)\n",
      "Requirement already satisfied: docker<7.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (6.1.3)\n",
      "Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.6.4)\n",
      "Requirement already satisfied: argcomplete<3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.1.2)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.23 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.26.17)\n",
      "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (41.0.4)\n",
      "Requirement already satisfied: azure-mgmt-network==21.0.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (21.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.8.2)\n",
      "Requirement already satisfied: azure-mgmt-authorization<4,>=0.40.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.0.0)\n",
      "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.7.1)\n",
      "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.3.1)\n",
      "Requirement already satisfied: ndg-httpsclient<=0.5.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.5.1)\n",
      "Requirement already satisfied: msal-extensions<=1.0.0,>=0.3.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.0.0)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.1.28)\n",
      "Requirement already satisfied: jsonpickle<4.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.0.2)\n",
      "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.2.7)\n",
      "Requirement already satisfied: knack~=0.10.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.10.1)\n",
      "Requirement already satisfied: humanfriendly<11.0,>=4.7 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (10.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2023.3.post1)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-mgmt-network==21.0.1->azureml-core) (1.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core<2.0.0->azureml-core) (1.16.0)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-mgmt-containerregistry<11,>=8.2.0->azureml-core) (0.6.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker<7.0.0->azureml-core) (1.6.3)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker<7.0.0->azureml-core) (306)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly<11.0,>=4.7->azureml-core) (3.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack~=0.10.0->azureml-core) (6.0.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack~=0.10.0->azureml-core) (0.9.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack~=0.10.0->azureml-core) (2.16.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msal-extensions<=1.0.0,>=0.3.0->azureml-core) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (2022.12.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (1.3.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ndg-httpsclient<=0.5.1->azureml-core) (0.5.0)\n",
      "Requirement already satisfied: pynacl>=1.5 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (4.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.3.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.7.1)\n",
      "Requirement already satisfied: jeepney>=0.6 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SecretStorage<4.0.0->azureml-core) (0.8.0)\n",
      "Requirement already satisfied: backports.weakref in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from backports.tempfile->azureml-core) (1.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core) (2.21)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Install needed packages\n",
    "%pip install opencv-python torch torchvision torchaudio azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import cv2\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "\n",
    "## Using torchvision to create a dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone source code from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "## curl source code from github\n",
    "!wget 'https://github.com/nnvu-fit/iusai-project/archive/refs/heads/main.zip' -O main.zip\n",
    "!unzip main.zip\n",
    "!mv iusai-project-main/* .\n",
    "!rm -rf iusai-project-main main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Workspace.create(name='ws-vunn-iusai-sea-sp6k7', subscription_id='d554f489-6933-4c33-8722-a536b3682bd7', resource_group='rg-vunn-iusai-sea-sp6k7'),\n",
       " {\n",
       "   \"name\": \"workspaceblobstore\",\n",
       "   \"container_name\": \"azureml-blobstore-5fddeec9-0fbc-4996-b95f-26996d3f3bcd\",\n",
       "   \"account_name\": \"wsvunniusaisea7140421596\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " })"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup Azure ML Workspace\n",
    "ws = Workspace.from_config()\n",
    "## From workspace, get/create the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "ws, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract dataset to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path:  videos/\n",
      "images_path:  images/\n"
     ]
    }
   ],
   "source": [
    "## define videos location + images output location\n",
    "video_path = 'videos/'\n",
    "images_path = 'images/'\n",
    "print('video_path: ', video_path)\n",
    "print('images_path: ', images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dict of videos/subject10/huangpi21.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject1/Yousef1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject11/alhashe31.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject13/guolingh1.avi (start): [['0', 0], ['6', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject12/makiluke1.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject14/chuangy61.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject15/bajajpak1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject16/dhingra51.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject17/zhoulian1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject18/yuqianyi1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject19/wangyus11.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dict of videos/subject21/Mark1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject23/vahid1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject22/yarub1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject2/Jourabloo1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject20/Cool1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject24/mustaffa1.avi (start): [['0', 0], ['1', 0], ['5', 0], ['2', 0]]\n",
      "Label dict of videos/subject4/meowseph1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject3/XiYin1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject5/Muath1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject6/husseinhijazi1.avi (start): [['0', 0], ['2', 0], ['1', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject7/zach1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject8/vaibhav1.avi (start): [['0', 0], ['3', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject9/chenlipi1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['5', 0], ['3', 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import v2i\n",
    "reload(v2i)\n",
    "from v2i import extract_images_from_videos\n",
    "import threading\n",
    "\n",
    "def extract_images_from_videos_collection(video_path, images_path):\n",
    "    ## get all videos file in video_path\n",
    "    video_list_location_collection = os.listdir(video_path)\n",
    "\n",
    "    ## define total_label_dict\n",
    "    ## create threading pool\n",
    "    thread = []\n",
    "    ## for each video file\n",
    "    for video_list_location in video_list_location_collection:\n",
    "        ## check if video_location is not a directory (i.e. is a file), then skip\n",
    "        if not os.path.isdir(video_path + video_list_location):\n",
    "            continue\n",
    "        ## list videos in video_location\n",
    "        thread.append(threading.Thread(target=extract_images_from_videos, args=(video_path + video_list_location, images_path, 1)))\n",
    "        # extract_images_from_videos(video_path + video_list_location, images_path, inteval=1)\n",
    "\n",
    "    ## start all threads\n",
    "    for t in thread: t.start()\n",
    "    ## wait for all threads to finish\n",
    "    for t in thread:\n",
    "        t.join()\n",
    "    \n",
    "    ## check images in images_path\n",
    "    images_list_location_collection = os.listdir(images_path)\n",
    "    print('images_list_location_collection: ', images_list_location_collection)\n",
    "\n",
    "# video_subject_6_path = video_path + '/subject6/'\n",
    "# ## list videos in video_location\n",
    "# label_dict = extract_images_from_videos(video_subject_6_path, images_path)\n",
    "\n",
    "## extract images from videos\n",
    "extract_images_from_videos_collection(video_path, images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Upload images to Azure data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from 'c:/Users/nnvuf/source/ai-final-project/images' to 'images-extra-small'\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', '/images-extra-small')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"22c174ee-e3e7-4e60-a949-e20eb237c73d\",\n",
       "    \"name\": \"images-extra-small\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"images-extra-small\",\n",
       "    \"workspace\": \"Workspace.create(name='ws-vunn-iusai-sea-sp6k7', subscription_id='d554f489-6933-4c33-8722-a536b3682bd7', resource_group='rg-vunn-iusai-sea-sp6k7')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## upload images to data asset using Dataset.File.upload_directory\n",
    "Dataset.File.upload_directory(src_dir=images_path, target=(ds, 'images-extra-small'), overwrite=True, show_progress=True) \\\n",
    "    .register(workspace=ws, name='images-extra-small', description='images-extra-small') ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setup public workspace endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_collection:  images-extra-small  is already registered\n",
      "dataset_collection:  images-small-v2  is already registered\n",
      "dataset_collection:  images-medium  is already registered\n"
     ]
    }
   ],
   "source": [
    "dataset_collection_list = ['images-extra-small', 'images-small-v2', 'images-medium']\n",
    "## register dataset using Dataset.File.from_files\n",
    "for dataset_collection in dataset_collection_list:\n",
    "    ## check if dataset_collection is already registered\n",
    "    if dataset_collection in ws.datasets.keys():\n",
    "        print('dataset_collection: ', dataset_collection, ' is already registered')\n",
    "        continue\n",
    "    Dataset.File.from_files(path=(ds, dataset_collection)) \\\n",
    "        .register(workspace=ws, name=dataset_collection, description=dataset_collection) ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train models\n",
    "1. ResNET\n",
    "2. DenseNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup device + load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import train and scrore function from train.py\n",
    "import train as t;\n",
    "reload(t)\n",
    "from train import train, score_model, get_device\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "images_path = 'images'\n",
    "images_ds_path = \"images-extra-small\"\n",
    "if not os.path.exists(images_path):\n",
    "    os.mkdir(images_path)\n",
    "# download data asset to local if images_path is empty\n",
    "if len(os.listdir(images_path)) == 0:\n",
    "    print('images_path is empty, download images_ds to images_path')\n",
    "    # download data asset to local\n",
    "    images_ds = Dataset.get_by_name(workspace=ws, name=images_ds_path)\n",
    "    images_ds.download(target_path=images_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import data_set as ds\n",
    "reload(ds)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "imageDataset = ds.ImageDataset('images', transform=transform)\n",
    "## define batch_size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  [0, 1, 2, 3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "image, label = imageDataset.get_image(0)\n",
    "# image.show()\n",
    "labels = imageDataset.labels()\n",
    "## show labels in Interger\n",
    "print('labels: ',  [int(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds:  18109\n",
      "val_ds:  4528\n",
      "test_ds:  2516\n"
     ]
    }
   ],
   "source": [
    "## split dataset into train and test dataset using random_split\n",
    "from torch.utils.data import random_split\n",
    "train_val_size = int(0.9 * len(imageDataset))\n",
    "test_size = len(imageDataset) - train_val_size\n",
    "train_val_ds, test_ds = random_split(imageDataset, [train_val_size, test_size])\n",
    "\n",
    "## split train_val_ds into train_ds and val_ds using random_split\n",
    "train_size = int(0.8 * len(train_val_ds))\n",
    "val_size = len(train_val_ds) - train_size\n",
    "train_ds, val_ds = random_split(train_val_ds, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "print('train_ds: ', len(train_ds))\n",
    "print('val_ds: ', len(val_ds))\n",
    "print('test_ds: ', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnes18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\notebook.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## train model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## score model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m score_model(model, loss_fn, test_dataloader, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\train.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, train_dataset, test_dataset, epochs, device)\u001b[0m\n\u001b[0;32m     33\u001b[0m   loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m   optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 35\u001b[0m   train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m train_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataset\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m     37\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train model\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4070, Test Loss: 0.4468, Total Time: 00 hours, 10 minutes, 50 seconds\n",
      "Epoch 2/10, Train Loss: 0.2953, Test Loss: 0.3624, Total Time: 00 hours, 12 minutes, 53 seconds\n",
      "Epoch 3/10, Train Loss: 0.2196, Test Loss: 0.3772, Total Time: 00 hours, 13 minutes, 49 seconds\n",
      "Epoch 4/10, Train Loss: 0.1600, Test Loss: 0.3560, Total Time: 00 hours, 16 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.1331, Test Loss: 0.3690, Total Time: 00 hours, 15 minutes, 54 seconds\n",
      "Epoch 6/10, Train Loss: 0.1037, Test Loss: 0.3158, Total Time: 00 hours, 15 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0790, Test Loss: 0.3453, Total Time: 00 hours, 15 minutes, 53 seconds\n",
      "Epoch 8/10, Train Loss: 0.0761, Test Loss: 0.4047, Total Time: 00 hours, 15 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0618, Test Loss: 0.3804, Total Time: 00 hours, 15 minutes, 21 seconds\n",
      "Epoch 10/10, Train Loss: 0.0561, Test Loss: 0.4284, Total Time: 00 hours, 16 minutes, 02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4667215104080109"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=100, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes18.100_epochs.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get denseNet model of image classification from torchvision\n",
    "model = torchvision.models.densenet121(pretrained=True, num_classes=len(labels))\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.6834, Test Loss: 0.7046, Total Time: 05 hours, 27 minutes, 36 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7259557617677225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4411, Test Loss: 0.6275, Total Time: 05 hours, 34 minutes, 19 seconds\n",
      "Epoch 2/10, Train Loss: 0.3439, Test Loss: 0.6895, Total Time: 05 hours, 34 minutes, 47 seconds\n",
      "Epoch 3/10, Train Loss: 0.2888, Test Loss: 0.4157, Total Time: 05 hours, 43 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.2428, Test Loss: 0.4163, Total Time: 05 hours, 35 minutes, 47 seconds\n",
      "Epoch 5/10, Train Loss: 0.2049, Test Loss: 0.3158, Total Time: 07 hours, 43 minutes, 43 seconds\n",
      "Epoch 6/10, Train Loss: 0.1741, Test Loss: 0.5003, Total Time: 08 hours, 44 minutes, 26 seconds\n",
      "Epoch 7/10, Train Loss: 0.1587, Test Loss: 0.3826, Total Time: 08 hours, 34 minutes, 52 seconds\n",
      "Epoch 8/10, Train Loss: 0.1292, Test Loss: 0.3596, Total Time: 08 hours, 28 minutes, 02 seconds\n",
      "Epoch 9/10, Train Loss: 0.1110, Test Loss: 0.4189, Total Time: 17 hours, 53 minutes, 29 seconds\n",
      "Epoch 10/10, Train Loss: 0.1113, Test Loss: 0.3861, Total Time: 08 hours, 27 minutes, 54 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41211051089964534"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_densenet121.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Yolov5 to extract face then using ResNet to classification the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use yoloresnet model\n",
    "import model\n",
    "reload(model)\n",
    "from model import YoloResnet\n",
    "model = YoloResnet()\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_yoloresnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
