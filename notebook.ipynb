{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "## Outline\n",
    "1. Import Library\n",
    "2. Setup pre-requisites\n",
    "3. Extract dataset to images\n",
    "4. Upload images to Azure data store\n",
    "4. Setting up Azure ML Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: torch in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting azureml-core\n",
      "  Obtaining dependency information for azureml-core from https://files.pythonhosted.org/packages/e5/da/ed67a11a1baa8dff268ce71965fb936cd39e244ddd82134c3325f89fa7a8/azureml_core-1.53.0-py3-none-any.whl.metadata\n",
      "  Using cached azureml_core-1.53.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from opencv-python) (1.26.1)\n",
      "Requirement already satisfied: filelock in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: requests in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: pytz in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from azureml-core) (2023.3.post1)\n",
      "Collecting backports.tempfile (from azureml-core)\n",
      "  Using cached backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pathspec<1.0.0 (from azureml-core)\n",
      "  Obtaining dependency information for pathspec<1.0.0 from https://files.pythonhosted.org/packages/b4/2a/9b1be29146139ef459188f5e420a66e835dda921208db600b7037093891f/pathspec-0.11.2-py3-none-any.whl.metadata\n",
      "  Using cached pathspec-0.11.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0 (from azureml-core)\n",
      "  Obtaining dependency information for msal<2.0.0,>=1.15.0 from https://files.pythonhosted.org/packages/35/33/0fd933b627879a9855d02a83a57929b45d0bdbeb050ddd63109cc404fbf6/msal-1.24.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached msal-1.24.1-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0 (from azureml-core)\n",
      "  Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting knack~=0.10.0 (from azureml-core)\n",
      "  Using cached knack-0.10.1-py3-none-any.whl (61 kB)\n",
      "Collecting azure-core<2.0.0 (from azureml-core)\n",
      "  Obtaining dependency information for azure-core<2.0.0 from https://files.pythonhosted.org/packages/98/3a/d53e2b8a75c448ef45d7ae4b0659eb6c0d48978f25a709e2a39894a48704/azure_core-1.29.4-py3-none-any.whl.metadata\n",
      "  Using cached azure_core-1.29.4-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pkginfo (from azureml-core)\n",
      "  Using cached pkginfo-1.9.6-py3-none-any.whl (30 kB)\n",
      "Collecting argcomplete<3 (from azureml-core)\n",
      "  Using cached argcomplete-2.1.2-py3-none-any.whl (37 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7 (from azureml-core)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core)\n",
      "  Obtaining dependency information for paramiko<4.0.0,>=2.0.8 from https://files.pythonhosted.org/packages/bb/8f/3cef65d3fe76e59f320405027d594a0332e44852fef722f0ee4e81e2e7e3/paramiko-3.3.1-py3-none-any.whl.metadata\n",
      "  Using cached paramiko-3.3.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting azure-mgmt-resource<=22.0.0,>=15.0.0 (from azureml-core)\n",
      "  Using cached azure_mgmt_resource-22.0.0-py3-none-any.whl (2.4 MB)\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0 (from azureml-core)\n",
      "  Obtaining dependency information for azure-mgmt-containerregistry<11,>=8.2.0 from https://files.pythonhosted.org/packages/2c/67/5e4a94ebe42bb28317be58e7d11d823b318e9eb6b5c6d3cf8b13670b5b06/azure_mgmt_containerregistry-10.2.0-py3-none-any.whl.metadata\n",
      "  Using cached azure_mgmt_containerregistry-10.2.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting azure-mgmt-storage<=21.0.0,>=16.0.0 (from azureml-core)\n",
      "  Using cached azure_mgmt_storage-21.0.0-py3-none-any.whl (2.8 MB)\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0 (from azureml-core)\n",
      "  Obtaining dependency information for azure-mgmt-keyvault<11.0.0,>=0.40.0 from https://files.pythonhosted.org/packages/14/be/66c3d7ce8e32e4eb32a7f4eaa99f6c12a3f1932f86c9d182440bba563754/azure_mgmt_keyvault-10.2.3-py3-none-any.whl.metadata\n",
      "  Using cached azure_mgmt_keyvault-10.2.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting azure-mgmt-authorization<4,>=0.40.0 (from azureml-core)\n",
      "  Using cached azure_mgmt_authorization-3.0.0-py3-none-any.whl (965 kB)\n",
      "Collecting azure-mgmt-network==21.0.1 (from azureml-core)\n",
      "  Using cached azure_mgmt_network-21.0.1-py3-none-any.whl (8.9 MB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core)\n",
      "  Using cached azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core)\n",
      "  Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33 (from azureml-core)\n",
      "  Using cached msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.23 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from azureml-core) (1.26.16)\n",
      "Collecting packaging<=23.0,>=20.0 (from azureml-core)\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from azureml-core) (41.0.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from azureml-core) (2.8.2)\n",
      "Collecting ndg-httpsclient<=0.5.1 (from azureml-core)\n",
      "  Using cached ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting SecretStorage<4.0.0 (from azureml-core)\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting jsonpickle<4.0.0 (from azureml-core)\n",
      "  Obtaining dependency information for jsonpickle<4.0.0 from https://files.pythonhosted.org/packages/d3/25/6e0a450430b7aa194b0f515f64820fc619314faa289458b7dfca4a026114/jsonpickle-3.0.2-py3-none-any.whl.metadata\n",
      "  Using cached jsonpickle-3.0.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting contextlib2<22.0.0 (from azureml-core)\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting docker<7.0.0 (from azureml-core)\n",
      "  Obtaining dependency information for docker<7.0.0 from https://files.pythonhosted.org/packages/db/be/3032490fa33b36ddc8c4b1da3252c6f974e7133f1a50de00c6b85cca203a/docker-6.1.3-py3-none-any.whl.metadata\n",
      "  Using cached docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting PyJWT<3.0.0 (from azureml-core)\n",
      "  Obtaining dependency information for PyJWT<3.0.0 from https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl.metadata\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0 (from azureml-core)\n",
      "  Using cached adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: pyopenssl<24.0.0 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from azureml-core) (23.2.0)\n",
      "Collecting jmespath<2.0.0 (from azureml-core)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.3.1 (from azure-mgmt-network==21.0.1->azureml-core)\n",
      "  Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from azure-core<2.0.0->azureml-core) (1.16.0)\n",
      "Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-containerregistry<11,>=8.2.0->azureml-core)\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core) (1.15.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from docker<7.0.0->azureml-core) (0.58.0)\n",
      "Requirement already satisfied: pygments in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from knack~=0.10.0->azureml-core) (2.15.1)\n",
      "Requirement already satisfied: pyyaml in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from knack~=0.10.0->azureml-core) (6.0)\n",
      "Collecting tabulate (from knack~=0.10.0->azureml-core)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting portalocker<3,>=1.0 (from msal-extensions<=1.0.0,>=0.3.0->azureml-core)\n",
      "  Obtaining dependency information for portalocker<3,>=1.0 from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (2023.7.22)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest<=0.7.1,>=0.5.1->azureml-core)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient<=0.5.1->azureml-core)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core)\n",
      "  Using cached bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
      "Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core)\n",
      "  Using cached PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from requests->torchvision) (1.7.1)\n",
      "Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core)\n",
      "  Using cached jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core)\n",
      "  Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/nnvuf/anaconda3/envs/vunn-iusai-final/lib/python3.10/site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core) (2.21)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading azureml_core-1.53.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.29.4-py3-none-any.whl (192 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_mgmt_containerregistry-10.2.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_mgmt_keyvault-10.2.3-py3-none-any.whl (811 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.1/811.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-3.0.2-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.24.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading paramiko-3.3.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: backports.weakref, azure-common, tabulate, PyJWT, pyasn1, portalocker, pkginfo, pathspec, packaging, oauthlib, jsonpickle, jmespath, jeepney, isodate, humanfriendly, contextlib2, bcrypt, backports.tempfile, argcomplete, requests-oauthlib, pynacl, knack, docker, azure-core, SecretStorage, paramiko, msrest, azure-mgmt-core, adal, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, msal-extensions, azure-graphrbac, azureml-core\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "Successfully installed PyJWT-2.8.0 SecretStorage-3.3.3 adal-1.2.7 argcomplete-2.1.2 azure-common-1.1.28 azure-core-1.29.4 azure-graphrbac-0.61.1 azure-mgmt-authorization-3.0.0 azure-mgmt-containerregistry-10.2.0 azure-mgmt-core-1.4.0 azure-mgmt-keyvault-10.2.3 azure-mgmt-network-21.0.1 azure-mgmt-resource-22.0.0 azure-mgmt-storage-21.0.0 azureml-core-1.53.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 contextlib2-21.6.0 docker-6.1.3 humanfriendly-10.0 isodate-0.6.1 jeepney-0.8.0 jmespath-1.0.1 jsonpickle-3.0.2 knack-0.10.1 msal-1.24.1 msal-extensions-1.0.0 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.2 packaging-23.0 paramiko-3.3.1 pathspec-0.11.2 pkginfo-1.9.6 portalocker-2.8.2 pyasn1-0.5.0 pynacl-1.5.0 requests-oauthlib-1.3.1 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Install needed packages\n",
    "%pip install opencv-python torch torchvision torchaudio azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import cv2\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "\n",
    "## Using torchvision to create a dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Workspace.create(name='ws-vunn-iusai-sea-sp6k7', subscription_id='d554f489-6933-4c33-8722-a536b3682bd7', resource_group='rg-vunn-iusai-sea-sp6k7'),\n",
       " {\n",
       "   \"name\": \"workspaceblobstore\",\n",
       "   \"container_name\": \"azureml-blobstore-5fddeec9-0fbc-4996-b95f-26996d3f3bcd\",\n",
       "   \"account_name\": \"wsvunniusaisea7140421596\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " })"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup Azure ML Workspace\n",
    "ws = Workspace.from_config()\n",
    "## From workspace, get/create the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "ws, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract dataset to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path:  videos/\n",
      "images_path:  images/\n"
     ]
    }
   ],
   "source": [
    "## define videos location + images output location\n",
    "video_path = 'videos/'\n",
    "images_path = 'images/'\n",
    "print('video_path: ', video_path)\n",
    "print('images_path: ', images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dict of videos/subject10/huangpi21.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject11/alhashe31.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject1/Yousef1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject14/chuangy61.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject13/guolingh1.avi (start): [['0', 0], ['6', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject12/makiluke1.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject15/bajajpak1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject16/dhingra51.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject19/wangyus11.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject17/zhoulian1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject18/yuqianyi1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject21/Mark1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject2/Jourabloo1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject22/yarub1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject23/vahid1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject20/Cool1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject24/mustaffa1.avi (start): [['0', 0], ['1', 0], ['5', 0], ['2', 0]]\n",
      "Label dict of videos/subject3/XiYin1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject6/husseinhijazi1.avi (start): [['0', 0], ['2', 0], ['1', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject5/Muath1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject4/meowseph1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject7/zach1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject8/vaibhav1.avi (start): [['0', 0], ['3', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject9/chenlipi1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['5', 0], ['3', 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-5 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-24 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-13 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-27 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-23 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-21 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-19 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-26 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-16 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-18 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-22 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-17 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-12 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-28 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-7 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-25 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-20 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-11 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-15 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-8 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-9 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-14 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n",
      "Exception in thread Thread-6 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_list_location_collection:  ['0', '1', '2', '3', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "import v2i\n",
    "reload(v2i)\n",
    "from v2i import extract_images_from_videos\n",
    "import threading\n",
    "\n",
    "def extract_images_from_videos_collection(video_path, images_path):\n",
    "    ## get all videos file in video_path\n",
    "    video_list_location_collection = os.listdir(video_path)\n",
    "\n",
    "    ## define total_label_dict\n",
    "    ## create threading pool\n",
    "    thread = []\n",
    "    ## for each video file\n",
    "    for video_list_location in video_list_location_collection:\n",
    "        ## check if video_location is not a directory (i.e. is a file), then skip\n",
    "        if not os.path.isdir(video_path + video_list_location):\n",
    "            continue\n",
    "        ## list videos in video_location\n",
    "        thread.append(threading.Thread(target=extract_images_from_videos, args=(video_path + video_list_location, images_path, 1)))\n",
    "        # extract_images_from_videos(video_path + video_list_location, images_path, inteval=1)\n",
    "\n",
    "    ## start all threads\n",
    "    for t in thread: t.start()\n",
    "    ## wait for all threads to finish\n",
    "    for t in thread:\n",
    "        t.join()\n",
    "    \n",
    "    ## check images in images_path\n",
    "    images_list_location_collection = os.listdir(images_path)\n",
    "    print('images_list_location_collection: ', images_list_location_collection)\n",
    "\n",
    "# video_subject_6_path = video_path + '/subject6/'\n",
    "# ## list videos in video_location\n",
    "# label_dict = extract_images_from_videos(video_subject_6_path, images_path)\n",
    "\n",
    "## extract images from videos\n",
    "extract_images_from_videos_collection(video_path, images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Upload images to Azure data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from 'c:/Users/nnvuf/source/ai-final-project/images' to 'images-extra-small'\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', '/images-extra-small')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"22c174ee-e3e7-4e60-a949-e20eb237c73d\",\n",
       "    \"name\": \"images-extra-small\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"images-extra-small\",\n",
       "    \"workspace\": \"Workspace.create(name='ws-vunn-iusai-sea-sp6k7', subscription_id='d554f489-6933-4c33-8722-a536b3682bd7', resource_group='rg-vunn-iusai-sea-sp6k7')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## upload images to data asset using Dataset.File.upload_directory\n",
    "Dataset.File.upload_directory(src_dir=images_path, target=(ds, 'images-extra-small'), overwrite=True, show_progress=True) \\\n",
    "    .register(workspace=ws, name='images-extra-small', description='images-extra-small') ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setup public workspace endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_collection:  images-extra-small  is already registered\n",
      "dataset_collection:  images-small-v2  is already registered\n",
      "dataset_collection:  images-medium  is already registered\n"
     ]
    }
   ],
   "source": [
    "dataset_collection_list = ['images-extra-small', 'images-small-v2', 'images-medium']\n",
    "## register dataset using Dataset.File.from_files\n",
    "for dataset_collection in dataset_collection_list:\n",
    "    ## check if dataset_collection is already registered\n",
    "    if dataset_collection in ws.datasets.keys():\n",
    "        print('dataset_collection: ', dataset_collection, ' is already registered')\n",
    "        continue\n",
    "    Dataset.File.from_files(path=(ds, dataset_collection)) \\\n",
    "        .register(workspace=ws, name=dataset_collection, description=dataset_collection) ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train models\n",
    "1. ResNET\n",
    "2. DenseNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup device + load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import train and scrore function from train.py\n",
    "import train as t;\n",
    "reload(t)\n",
    "from train import train, score_model, get_device\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# download data asset to local if needed\n",
    "images_path = 'images'\n",
    "images_ds_path = \"images-extra-small\"\n",
    "if not os.path.exists(images_path):\n",
    "    os.mkdir(images_path)\n",
    "# download data asset to local if images_path is empty\n",
    "if len(os.listdir(images_path)) == 0:\n",
    "    print('images_path is empty, download images_ds to images_path')\n",
    "    images_ds = Dataset.File.from_files(path=(ds, images_ds_path)) \\\n",
    "        .register(workspace=ws, name=images_ds_path, description=images_ds_path)\n",
    "    images_ds.download(target_path=images_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import data_set as ds\n",
    "reload(ds)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "imageDataset = ds.ImageDataset('images', transform=transform)\n",
    "## define batch_size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  [0, 1, 2, 3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "image, label = imageDataset.get_image(0)\n",
    "# image.show()\n",
    "labels = imageDataset.labels()\n",
    "## show labels in Interger\n",
    "print('labels: ',  [int(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds:  37715\n",
      "val_ds:  9429\n",
      "test_ds:  5239\n"
     ]
    }
   ],
   "source": [
    "## split dataset into train and test dataset using random_split\n",
    "from torch.utils.data import random_split\n",
    "train_val_size = int(0.9 * len(imageDataset))\n",
    "test_size = len(imageDataset) - train_val_size\n",
    "train_val_ds, test_ds = random_split(imageDataset, [train_val_size, test_size])\n",
    "\n",
    "## split train_val_ds into train_ds and val_ds using random_split\n",
    "train_size = int(0.8 * len(train_val_ds))\n",
    "val_size = len(train_val_ds) - train_size\n",
    "train_ds, val_ds = random_split(train_val_ds, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "print('train_ds: ', len(train_ds))\n",
    "print('val_ds: ', len(val_ds))\n",
    "print('test_ds: ', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnes18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\notebook.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## train model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## score model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m score_model(model, loss_fn, test_dataloader, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\train.py:28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, train_dataset, test_dataset, epochs, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     27\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m train_dataset:\n\u001b[0;32m     29\u001b[0m   inputs, targets \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:362\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitems__\u001b[39m(\u001b[39mself\u001b[39m, indices: List[\u001b[39mint\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[T_co]:\n\u001b[0;32m    359\u001b[0m     \u001b[39m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[39m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m--> 362\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m         \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\data_set.py:20\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     18\u001b[0m x \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(path_x)\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> 20\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(x)\n\u001b[0;32m     21\u001b[0m \u001b[39m## [0, 1, 2]: index == -2 => 1;\u001b[39;00m\n\u001b[0;32m     22\u001b[0m label \u001b[39m=\u001b[39m path_x\u001b[39m.\u001b[39msplit(os\u001b[39m.\u001b[39msep)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m    354\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mresize(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mantialias)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    488\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    489\u001b[0m     pil_interpolation \u001b[39m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m--> 490\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mresize(img, size\u001b[39m=\u001b[39;49moutput_size, interpolation\u001b[39m=\u001b[39;49mpil_interpolation)\n\u001b[0;32m    492\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mresize(img, size\u001b[39m=\u001b[39moutput_size, interpolation\u001b[39m=\u001b[39minterpolation\u001b[39m.\u001b[39mvalue, antialias\u001b[39m=\u001b[39mantialias)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(size, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(size) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[0;32m    248\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot inappropriate size arg: \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mresize(\u001b[39mtuple\u001b[39;49m(size[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]), interpolation)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:2174\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2166\u001b[0m             \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mreduce(\u001b[39mself\u001b[39m, factor, box\u001b[39m=\u001b[39mreduce_box)\n\u001b[0;32m   2167\u001b[0m         box \u001b[39m=\u001b[39m (\n\u001b[0;32m   2168\u001b[0m             (box[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[0;32m   2169\u001b[0m             (box[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[0;32m   2170\u001b[0m             (box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[0;32m   2171\u001b[0m             (box[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[0;32m   2172\u001b[0m         )\n\u001b[1;32m-> 2174\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mresize(size, resample, box))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train model\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.2793, Test Loss: 0.3115\n",
      "Epoch 2/10, Train Loss: 0.1936, Test Loss: 0.2297\n",
      "Epoch 3/10, Train Loss: 0.1382, Test Loss: 0.2441\n",
      "Epoch 4/10, Train Loss: 0.1056, Test Loss: 0.2602\n",
      "Epoch 5/10, Train Loss: 0.0861, Test Loss: 0.2807\n",
      "Epoch 6/10, Train Loss: 0.0804, Test Loss: 0.2235\n",
      "Epoch 7/10, Train Loss: 0.0589, Test Loss: 0.2136\n",
      "Epoch 8/10, Train Loss: 0.0591, Test Loss: 0.2263\n",
      "Epoch 9/10, Train Loss: 0.0509, Test Loss: 0.2329\n",
      "Epoch 10/10, Train Loss: 0.0417, Test Loss: 0.2341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23411470530744863"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24655256064399098"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(model, loss_fn, val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes18.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get denseNet model of image classification from torchvision\n",
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\notebook.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## train model using device (CPU or GPU) 1 epoch\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## score model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m score_model(model, loss_fn, test_dataloader, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\train.py:33\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, train_dataset, test_dataset, epochs, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     32\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, targets)\n\u001b[1;32m---> 33\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_densenet121.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Yolov5 to extract face then using ResNet to classification the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use yoloresnet model\n",
    "import model\n",
    "reload(model)\n",
    "from model import YoloResnet\n",
    "model = YoloResnet()\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_yoloresnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
