{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "## Outline\n",
    "1. Import Library\n",
    "2. Setup pre-requisites\n",
    "3. Extract dataset to images\n",
    "4. Upload images to Azure data store\n",
    "4. Setting up Azure ML Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: torch in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: azureml-core in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.56.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.1/11.0 MB 374.1 kB/s eta 0:00:30\n",
      "     --------------------------------------- 0.1/11.0 MB 467.6 kB/s eta 0:00:24\n",
      "     --------------------------------------- 0.1/11.0 MB 467.6 kB/s eta 0:00:24\n",
      "     --------------------------------------- 0.1/11.0 MB 467.6 kB/s eta 0:00:24\n",
      "     --------------------------------------- 0.1/11.0 MB 276.8 kB/s eta 0:00:40\n",
      "      -------------------------------------- 0.2/11.0 MB 444.2 kB/s eta 0:00:25\n",
      "      -------------------------------------- 0.2/11.0 MB 444.2 kB/s eta 0:00:25\n",
      "      -------------------------------------- 0.2/11.0 MB 444.2 kB/s eta 0:00:25\n",
      "      -------------------------------------- 0.3/11.0 MB 424.5 kB/s eta 0:00:26\n",
      "     - ------------------------------------- 0.3/11.0 MB 453.2 kB/s eta 0:00:24\n",
      "     - ------------------------------------- 0.3/11.0 MB 487.6 kB/s eta 0:00:22\n",
      "     - ------------------------------------- 0.4/11.0 MB 527.0 kB/s eta 0:00:21\n",
      "     - ------------------------------------- 0.4/11.0 MB 534.7 kB/s eta 0:00:20\n",
      "     - ------------------------------------- 0.5/11.0 MB 566.8 kB/s eta 0:00:19\n",
      "     - ------------------------------------- 0.5/11.0 MB 595.3 kB/s eta 0:00:18\n",
      "     - ------------------------------------- 0.5/11.0 MB 595.3 kB/s eta 0:00:18\n",
      "     -- ------------------------------------ 0.6/11.0 MB 633.3 kB/s eta 0:00:17\n",
      "     -- ------------------------------------ 0.7/11.0 MB 665.8 kB/s eta 0:00:16\n",
      "     -- ------------------------------------ 0.7/11.0 MB 625.9 kB/s eta 0:00:17\n",
      "     -- ------------------------------------ 0.7/11.0 MB 654.8 kB/s eta 0:00:16\n",
      "     -- ------------------------------------ 0.8/11.0 MB 682.7 kB/s eta 0:00:15\n",
      "     -- ------------------------------------ 0.8/11.0 MB 689.6 kB/s eta 0:00:15\n",
      "     --- ----------------------------------- 0.9/11.0 MB 713.1 kB/s eta 0:00:15\n",
      "     --- ----------------------------------- 0.9/11.0 MB 736.0 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.0/11.0 MB 764.3 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.1/11.0 MB 774.5 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.1/11.0 MB 793.3 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.2/11.0 MB 802.9 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.3/11.0 MB 832.9 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.3/11.0 MB 840.6 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.4/11.0 MB 841.6 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.4/11.0 MB 857.0 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.5/11.0 MB 885.7 kB/s eta 0:00:11\n",
      "     ----- --------------------------------- 1.5/11.0 MB 879.4 kB/s eta 0:00:11\n",
      "     ----- --------------------------------- 1.6/11.0 MB 884.9 kB/s eta 0:00:11\n",
      "     ----- --------------------------------- 1.6/11.0 MB 903.7 kB/s eta 0:00:11\n",
      "     ------ -------------------------------- 1.7/11.0 MB 919.4 kB/s eta 0:00:11\n",
      "     ------ -------------------------------- 1.8/11.0 MB 923.6 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 1.9/11.0 MB 936.1 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 1.9/11.0 MB 944.8 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 2.0/11.0 MB 948.1 kB/s eta 0:00:10\n",
      "     ------- ------------------------------- 2.0/11.0 MB 958.5 kB/s eta 0:00:10\n",
      "     ------- ------------------------------- 2.1/11.0 MB 975.7 kB/s eta 0:00:10\n",
      "     ------- ------------------------------- 2.2/11.0 MB 975.7 kB/s eta 0:00:10\n",
      "     ------- ------------------------------- 2.2/11.0 MB 989.6 kB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.3/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.4/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.5/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 2.5/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 2.6/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.7/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.7/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.8/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.9/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.9/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.0/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.1/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.2/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.2/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.3/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.4/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.5/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 3.6/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 3.7/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 3.7/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "     -------------- ------------------------- 3.9/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.0/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.1/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.2/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.3/11.0 MB 1.3 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 4.4/11.0 MB 1.3 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 4.5/11.0 MB 1.3 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 4.6/11.0 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 4.8/11.0 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 4.9/11.0 MB 1.3 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 5.0/11.0 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 5.2/11.0 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 5.3/11.0 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 5.4/11.0 MB 1.4 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 5.6/11.0 MB 1.4 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 5.7/11.0 MB 1.5 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 5.9/11.0 MB 1.5 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 6.1/11.0 MB 1.5 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 6.2/11.0 MB 1.5 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 6.4/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 6.5/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 6.7/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 6.9/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 7.0/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 7.2/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 7.3/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 7.5/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 7.7/11.0 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.8/11.0 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 8.1/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 8.2/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 8.4/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 8.6/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 8.7/11.0 MB 1.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 8.8/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 8.9/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 9.0/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 9.1/11.0 MB 1.9 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 9.3/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.5/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.6/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.8/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 10.0/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.2/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.3/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.6/11.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.8/11.0 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  11.0/11.0 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 11.0/11.0 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: networkx in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nnvuf\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: azure-mgmt-network<=26.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (25.4.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.9.0.post0)\n",
      "Requirement already satisfied: jsonpickle<4.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.2.2)\n",
      "Requirement already satisfied: packaging<=25.0,>=20.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (24.0)\n",
      "Requirement already satisfied: argcomplete<4 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.4.0)\n",
      "Requirement already satisfied: PyJWT<3.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.8.0)\n",
      "Requirement already satisfied: humanfriendly<11.0,>=4.7 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (10.0)\n",
      "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.4.0)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (10.3.0)\n",
      "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.7.1)\n",
      "Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.6.4)\n",
      "Requirement already satisfied: pkginfo in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.11.1)\n",
      "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.2.7)\n",
      "Requirement already satisfied: azure-core<2.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.30.2)\n",
      "Requirement already satisfied: urllib3<3.0.0,>1.26.17 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.2.2)\n",
      "Requirement already satisfied: azure-mgmt-storage<=22.0.0,>=16.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (21.2.1)\n",
      "Requirement already satisfied: SecretStorage<4.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (3.3.3)\n",
      "Requirement already satisfied: pathspec<1.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.12.1)\n",
      "Requirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.2.0)\n",
      "Requirement already satisfied: pyopenssl<25.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (24.2.1)\n",
      "Requirement already satisfied: jmespath<2.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.0.1)\n",
      "Requirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (23.1.1)\n",
      "Requirement already satisfied: knack<0.12.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.11.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2024.1)\n",
      "Requirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.32.3)\n",
      "Requirement already satisfied: docker<8.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (7.1.0)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.1.28)\n",
      "Requirement already satisfied: backports.tempfile in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.0)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.15.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.30.0)\n",
      "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (10.3.1)\n",
      "Requirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (4.0.0)\n",
      "Requirement already satisfied: contextlib2<22.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (21.6.0)\n",
      "Requirement already satisfied: ndg-httpsclient<=0.5.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.5.1)\n",
      "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.61.1)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "     --------------------- ---------------- 174.1/301.8 kB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  297.0/301.8 kB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 301.8/301.8 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: cryptography>=1.1.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from adal<=1.2.7,>=1.2.0->azureml-core) (43.0.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core<2.0.0->azureml-core) (1.16.0)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core) (0.6.1)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core) (1.4.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\nnvuf\\appdata\\roaming\\python\\python310\\site-packages (from docker<8.0.0->azureml-core) (306)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly<11.0,>=4.7->azureml-core) (3.4.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack<0.12.0->azureml-core) (0.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack<0.12.0->azureml-core) (6.0.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\nnvuf\\appdata\\roaming\\python\\python310\\site-packages (from knack<0.12.0->azureml-core) (2.18.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core) (2.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (2024.7.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (2.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ndg-httpsclient<=0.5.1->azureml-core) (0.6.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (4.1.3)\n",
      "Requirement already satisfied: pynacl>=1.5 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (3.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (1.7.1)\n",
      "Requirement already satisfied: jeepney>=0.6 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SecretStorage<4.0.0->azureml-core) (0.8.0)\n",
      "Requirement already satisfied: backports.weakref in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from backports.tempfile->azureml-core) (1.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core) (3.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core) (2.22)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Install needed packages\n",
    "%pip install opencv-python torch torchvision torchaudio azureml-core scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import cv2\n",
    "# from azureml.core import Workspace, Dataset, Datastore\n",
    "\n",
    "## Using torchvision to create a dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone source code from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-22 19:33:20--  https://github.com/nnvu-fit/iusai-project/archive/refs/heads/main.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/nnvu-fit/iusai-project/zip/refs/heads/main [following]\n",
      "--2024-07-22 19:33:21--  https://codeload.github.com/nnvu-fit/iusai-project/zip/refs/heads/main\n",
      "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
      "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘main.zip’\n",
      "\n",
      "main.zip                [  <=>               ] 307,35K  1,46MB/s    in 0,2s    \n",
      "\n",
      "2024-07-22 19:33:21 (1,46 MB/s) - ‘main.zip’ saved [314727]\n",
      "\n",
      "Archive:  main.zip\n",
      "30c6d623a5535529b640fc32926bb83022b6ba2c\n",
      "   creating: iusai-project-main/\n",
      "   creating: iusai-project-main/.devcontainer/\n",
      "  inflating: iusai-project-main/.devcontainer/devcontainer.json  \n",
      "  inflating: iusai-project-main/.gitignore  \n",
      "   creating: iusai-project-main/.vscode/\n",
      "  inflating: iusai-project-main/.vscode/launch.json  \n",
      "  inflating: iusai-project-main/.vscode/settings.json  \n",
      "  inflating: iusai-project-main/Classification.ipynb  \n",
      "  inflating: iusai-project-main/Dockerfile  \n",
      " extracting: iusai-project-main/README.md  \n",
      "  inflating: iusai-project-main/config.json  \n",
      "  inflating: iusai-project-main/data_set.py  \n",
      "  inflating: iusai-project-main/image_classification_online.ipynb  \n",
      "  inflating: iusai-project-main/model.py  \n",
      "  inflating: iusai-project-main/notebook.ipynb  \n",
      "  inflating: iusai-project-main/requirements.txt  \n",
      "   creating: iusai-project-main/terraform/\n",
      " extracting: iusai-project-main/terraform/main.tf  \n",
      " extracting: iusai-project-main/terraform/provider.tf  \n",
      "   creating: iusai-project-main/the_app/\n",
      "   creating: iusai-project-main/the_app/helper/\n",
      "  inflating: iusai-project-main/the_app/helper/image_helper.py  \n",
      "  inflating: iusai-project-main/the_app/helper/model_helper.py  \n",
      "   creating: iusai-project-main/the_app/pages/\n",
      "  inflating: iusai-project-main/the_app/pages/classification.py  \n",
      "  inflating: iusai-project-main/the_app/streamlit_app.py  \n",
      "  inflating: iusai-project-main/train.py  \n",
      "  inflating: iusai-project-main/v2i.py  \n"
     ]
    }
   ],
   "source": [
    "## curl source code from github\n",
    "!wget 'https://github.com/nnvu-fit/iusai-project/archive/refs/heads/main.zip' -O main.zip\n",
    "!unzip main.zip\n",
    "!mv iusai-project-main/* .\n",
    "!rm -rf iusai-project-main main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "ename": "UserErrorException",
     "evalue": "UserErrorException:\n\tMessage: You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \\n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \\n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Setup Azure ML Workspace\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ws \u001b[38;5;241m=\u001b[39m \u001b[43mWorkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## From workspace, get/create the default datastore\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ds \u001b[38;5;241m=\u001b[39m ws\u001b[38;5;241m.\u001b[39mget_default_datastore()\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\workspace.py:292\u001b[0m, in \u001b[0;36mWorkspace.from_config\u001b[1;34m(path, auth, _logger, _file_name)\u001b[0m\n\u001b[0;32m    288\u001b[0m subscription_id, resource_group, workspace_name \u001b[38;5;241m=\u001b[39m project_info\u001b[38;5;241m.\u001b[39mget_workspace_info(\n\u001b[0;32m    289\u001b[0m     found_path)\n\u001b[0;32m    291\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound the config file in: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, found_path)\n\u001b[1;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWorkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\workspace.py:607\u001b[0m, in \u001b[0;36mWorkspace.get\u001b[1;34m(name, auth, subscription_id, resource_group, location, cloud, id)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m auth:\n\u001b[0;32m    605\u001b[0m     auth \u001b[38;5;241m=\u001b[39m InteractiveLoginAuthentication()\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWorkspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_cloud\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcloud\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_workspace_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\workspace.py:205\u001b[0m, in \u001b[0;36mWorkspace.__init__\u001b[1;34m(self, subscription_id, resource_group, workspace_name, auth, _location, _disable_service_check, _workspace_id, sku, tags, _cloud)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_autorest_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _disable_service_check:\n\u001b[1;32m--> 205\u001b[0m     auto_rest_workspace \u001b[38;5;241m=\u001b[39m \u001b[43m_commands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_workspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_workspace_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_autorest_object \u001b[38;5;241m=\u001b[39m auto_rest_workspace\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\_project\\_commands.py:467\u001b[0m, in \u001b[0;36mget_workspace\u001b[1;34m(auth, subscription_id, resource_group_name, workspace_name, location, cloud, workspace_id)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         workspaces \u001b[38;5;241m=\u001b[39m \u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_service_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAzureMachineLearningWorkspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mworkspaces\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m WorkspacesOperations\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    471\u001b[0m             workspaces,\n\u001b[0;32m    472\u001b[0m             resource_group_name,\n\u001b[0;32m    473\u001b[0m             workspace_name)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ClientRequestError:\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;66;03m# this most likely is because of failure to talk to arm.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;66;03m# Provide error message to user if they are in synapse enviroment.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# Additional params will enable aml dataplane get workspace call. \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\authentication.py:230\u001b[0m, in \u001b[0;36mAbstractAuthentication._get_service_client\u001b[1;34m(self, client_class, subscription_id, subscription_bound, base_url, is_check_subscription)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subscription_id \u001b[38;5;129;01mand\u001b[39;00m is_check_subscription:\n\u001b[0;32m    229\u001b[0m     all_subscription_list, tenant_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_subscription_ids()\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_subscription_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_subscription_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_url:\n\u001b[0;32m    233\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_type\u001b[38;5;241m.\u001b[39mendpoints\u001b[38;5;241m.\u001b[39mresource_manager\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\authentication.py:681\u001b[0m, in \u001b[0;36mInteractiveLoginAuthentication._check_if_subscription_exists\u001b[1;34m(self, subscription_id, subscription_id_list, tenant_id)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_if_subscription_exists\u001b[39m(\u001b[38;5;28mself\u001b[39m, subscription_id, subscription_id_list, tenant_id):\n\u001b[1;32m--> 681\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mInteractiveLoginAuthentication\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_subscription_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43msubscription_id_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\authentication.py:338\u001b[0m, in \u001b[0;36mAbstractAuthentication._check_if_subscription_exists\u001b[1;34m(self, subscription_id, subscription_id_list, tenant_id)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like you have specified subscription name, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, instead of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription id. Subscription names may not be unique, please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription id from this list \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subscription_id,\n\u001b[0;32m    336\u001b[0m                                                                            subscription_id_list))\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are currently logged-in to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m tenant. You don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have access \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    339\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m subscription, please check if it is in this tenant. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    340\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll the subscriptions that you have access to in this tenant are = \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    341\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Please refer to aka.ms/aml-notebook-auth for different \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    342\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthentication mechanisms in azureml-sdk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tenant_id,\n\u001b[0;32m    343\u001b[0m                                                                                 subscription_id,\n\u001b[0;32m    344\u001b[0m                                                                                 subscription_id_list))\n",
      "\u001b[1;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \\n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \\n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "## Setup Azure ML Workspace\n",
    "ws = Workspace.from_config()\n",
    "## From workspace, get/create the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "ws, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract dataset to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path:  videos/\n",
      "images_path:  subjects-small/\n"
     ]
    }
   ],
   "source": [
    "## define videos location + images output location\n",
    "video_path = 'videos/'\n",
    "images_path = 'subjects-small/'\n",
    "print('video_path: ', video_path)\n",
    "print('images_path: ', images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dict of videos/subject11/alhashe31.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject13/guolingh1.avi (start): [['0', 0], ['6', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject10/huangpi21.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject12/makiluke1.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject15/bajajpak1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject14/chuangy61.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject1/Yousef1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject16/dhingra51.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject17/zhoulian1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject21/Mark1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject2/Jourabloo1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject19/wangyus11.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject20/Cool1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject18/yuqianyi1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject22/yarub1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject23/vahid1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject5/Muath1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject4/meowseph1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject3/XiYin1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject24/mustaffa1.avi (start): [['0', 0], ['1', 0], ['5', 0], ['2', 0]]\n",
      "Label dict of videos/subject6/husseinhijazi1.avi (start): [['0', 0], ['2', 0], ['1', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject9/chenlipi1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['5', 0], ['3', 0]]\n",
      "Label dict of videos/subject8/vaibhav1.avi (start): [['0', 0], ['3', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject7/zach1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject1/Yousef1.avi (end): [['0', 0], ['1', 0], ['2', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject3/XiYin1.avi (end): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject20/Cool1.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject17/zhoulian1.avi (end): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject21/Mark1.avi (end): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject24/mustaffa1.avi (end): [['0', 0], ['1', 0], ['5', 0], ['2', 0]]\n",
      "Label dict of videos/subject22/yarub1.avi (end): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject7/zach1.avi (end): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject14/chuangy61.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject5/Muath1.avi (end): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject6/husseinhijazi1.avi (end): [['0', 0], ['2', 0], ['1', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject2/Jourabloo1.avi (end): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject4/meowseph1.avi (end): [['0', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject11/alhashe31.avi (end): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject16/dhingra51.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject13/guolingh1.avi (end): [['0', 0], ['6', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject23/vahid1.avi (end): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject8/vaibhav1.avi (end): [['0', 0], ['3', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject15/bajajpak1.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject9/chenlipi1.avi (end): [['0', 0], ['6', 0], ['1', 0], ['5', 0], ['3', 0]]\n",
      "Label dict of videos/subject18/yuqianyi1.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject10/huangpi21.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject19/wangyus11.avi (end): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject12/makiluke1.avi (end): [['0', 0], ['2', 0]]\n",
      "images_list_location_collection:  ['subject1', 'subject10', 'subject11', 'subject12', 'subject13', 'subject14', 'subject15', 'subject16', 'subject17', 'subject18', 'subject19', 'subject2', 'subject20', 'subject21', 'subject22', 'subject23', 'subject24', 'subject3', 'subject4', 'subject5', 'subject6', 'subject7', 'subject8', 'subject9']\n"
     ]
    }
   ],
   "source": [
    "import v2i\n",
    "reload(v2i)\n",
    "from v2i import extract_images_from_videos\n",
    "import threading\n",
    "\n",
    "def extract_images_from_videos_collection(video_path, images_path):\n",
    "    ## get all videos file in video_path\n",
    "    video_list_location_collection = os.listdir(video_path)\n",
    "\n",
    "    ## define total_label_dict\n",
    "    ## create threading pool\n",
    "    thread = []\n",
    "    ## for each video file\n",
    "    for video_list_location in video_list_location_collection:\n",
    "        ## check if video_location is not a directory (i.e. is a file), then skip\n",
    "        if not os.path.isdir(video_path + video_list_location):\n",
    "            continue\n",
    "        ## list videos in video_location\n",
    "        thread.append(threading.Thread(target=extract_images_from_videos, args=(video_path + video_list_location, images_path, 1)))\n",
    "        # extract_images_from_videos(video_path + video_list_location, images_path, inteval=1)\n",
    "\n",
    "    ## start all threads\n",
    "    for t in thread: t.start()\n",
    "    ## wait for all threads to finish\n",
    "    for t in thread:\n",
    "        t.join()\n",
    "    \n",
    "    ## check images in images_path\n",
    "    images_list_location_collection = os.listdir(images_path)\n",
    "    print('images_list_location_collection: ', images_list_location_collection)\n",
    "\n",
    "# video_subject_6_path = video_path + '/subject6-###'\n",
    "# ## list videos in video_location\n",
    "# label_dict = extract_images_from_videos(video_subject_6_path, images_path)\n",
    "\n",
    "## extract images from videos\n",
    "extract_images_from_videos_collection(video_path, images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Upload images to Azure data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from 'c:/Users/nnvuf/source/ai-final-project/images' to 'images-extra-small'\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', '/images-extra-small')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"22c174ee-e3e7-4e60-a949-e20eb237c73d\",\n",
       "    \"name\": \"images-extra-small\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"images-extra-small\",\n",
       "    \"workspace\": \"Workspace.create(name='ws-vunn-iusai-sea-sp6k7', subscription_id='d554f489-6933-4c33-8722-a536b3682bd7', resource_group='rg-vunn-iusai-sea-sp6k7')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## upload images to data asset using Dataset.File.upload_directory\n",
    "Dataset.File.upload_directory(src_dir=images_path, target=(ds, 'images-extra-small'), overwrite=True, show_progress=True) \\\n",
    "    .register(workspace=ws, name='images-extra-small', description='images-extra-small') ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setup public workspace endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_collection:  images-extra-small  is already registered\n",
      "dataset_collection:  images-small-v2  is already registered\n",
      "dataset_collection:  images-medium  is already registered\n"
     ]
    }
   ],
   "source": [
    "dataset_collection_list = ['images-extra-small', 'images-small-v2', 'images-medium']\n",
    "## register dataset using Dataset.File.from_files\n",
    "for dataset_collection in dataset_collection_list:\n",
    "    ## check if dataset_collection is already registered\n",
    "    if dataset_collection in ws.datasets.keys():\n",
    "        print('dataset_collection: ', dataset_collection, ' is already registered')\n",
    "        continue\n",
    "    Dataset.File.from_files(path=(ds, dataset_collection)) \\\n",
    "        .register(workspace=ws, name=dataset_collection, description=dataset_collection) ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train models\n",
    "1. ResNET\n",
    "2. DenseNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup device + load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_path is empty, download images_ds to images_path\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_path is empty, download images_ds to images_path\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# download data asset to local\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m images_ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mget_by_name(workspace\u001b[38;5;241m=\u001b[39mws, name\u001b[38;5;241m=\u001b[39mimages_ds_path)\n\u001b[1;32m     10\u001b[0m images_ds\u001b[38;5;241m.\u001b[39mdownload(target_path\u001b[38;5;241m=\u001b[39mimages_path, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "images_path = 'images'\n",
    "images_ds_path = \"images-extra-small\"\n",
    "if not os.path.exists(images_path):\n",
    "    os.mkdir(images_path)\n",
    "# download data asset to local if images_path is empty\n",
    "if len(os.listdir(images_path)) == 0:\n",
    "    print('images_path is empty, download images_ds to images_path')\n",
    "    # download data asset to local\n",
    "    images_ds = Dataset.get_by_name(workspace=ws, name=images_ds_path)\n",
    "    images_ds.download(target_path=images_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import data_set as ds\n",
    "reload(ds)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "imageDataset = ds.ImageDataset('subjects-small', transform=transform)\n",
    "## define batch_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['subject1', 'subject10', 'subject11', 'subject12', 'subject13', 'subject14', 'subject15', 'subject16', 'subject17', 'subject18', 'subject19', 'subject2', 'subject20', 'subject21', 'subject22', 'subject23', 'subject24', 'subject3', 'subject4', 'subject5', 'subject6', 'subject7', 'subject8', 'subject9']\n"
     ]
    }
   ],
   "source": [
    "image, label = imageDataset.get_image(0)\n",
    "# image.show()\n",
    "labels = imageDataset.labels()\n",
    "## show labels in Interger\n",
    "print('labels: ',  labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val_ds:  22637\n",
      "test_ds:  2516\n"
     ]
    }
   ],
   "source": [
    "## split dataset into train and test dataset using random_split\n",
    "from torch.utils.data import random_split\n",
    "train_val_size = int(0.9 * len(imageDataset))\n",
    "test_size = len(imageDataset) - train_val_size\n",
    "train_val_ds, test_ds = random_split(imageDataset, [train_val_size, test_size])\n",
    "\n",
    "## split train_val_ds into train_ds and val_ds using random_split\n",
    "train_size = int(0.8 * len(train_val_ds))\n",
    "val_size = len(train_val_ds) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_val_ds, [train_size, val_size])\n",
    "\n",
    "print('train_val_ds: ', len(train_val_ds))\n",
    "print('test_ds: ', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnes18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## import train and scrore function from train.py\n",
    "import train as t\n",
    "reload(t)\n",
    "from train import Trainer\n",
    "\n",
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn\n",
    "\n",
    "trainer = Trainer(model, optimizer, loss_fn, random_seed_value=86)\n",
    "\n",
    "print('device: ', trainer.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5: "
     ]
    }
   ],
   "source": [
    "## train model\n",
    "avg_lost = trainer.cross_validate(train_val_ds, epochs=5)\n",
    "print('avg_lost: ', avg_lost)\n",
    "## score model\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "trainer.score(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes18.100_epochs.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnes34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.resnet34(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes34.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\notebook.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## train model\u001b[39;00m\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## score model\u001b[39;00m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m score_model(model, loss_fn, test_dataloader, device\u001b[39m=\u001b[39mdevice)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\train.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, train_dataset, test_dataset, epochs, device)\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m   loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;32m     34\u001b[0m   optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m---> 35\u001b[0m   train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;32m     36\u001b[0m train_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataset\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[0;32m     37\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train model\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4070, Test Loss: 0.4468, Total Time: 00 hours, 10 minutes, 50 seconds\n",
      "Epoch 2/10, Train Loss: 0.2953, Test Loss: 0.3624, Total Time: 00 hours, 12 minutes, 53 seconds\n",
      "Epoch 3/10, Train Loss: 0.2196, Test Loss: 0.3772, Total Time: 00 hours, 13 minutes, 49 seconds\n",
      "Epoch 4/10, Train Loss: 0.1600, Test Loss: 0.3560, Total Time: 00 hours, 16 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.1331, Test Loss: 0.3690, Total Time: 00 hours, 15 minutes, 54 seconds\n",
      "Epoch 6/10, Train Loss: 0.1037, Test Loss: 0.3158, Total Time: 00 hours, 15 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0790, Test Loss: 0.3453, Total Time: 00 hours, 15 minutes, 53 seconds\n",
      "Epoch 8/10, Train Loss: 0.0761, Test Loss: 0.4047, Total Time: 00 hours, 15 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0618, Test Loss: 0.3804, Total Time: 00 hours, 15 minutes, 21 seconds\n",
      "Epoch 10/10, Train Loss: 0.0561, Test Loss: 0.4284, Total Time: 00 hours, 16 minutes, 02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4667215104080109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=100, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes18.100_epochs.small.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get denseNet model of image classification from torchvision\n",
    "model = torchvision.models.densenet121(pretrained=True, num_classes=len(labels))\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.6834, Test Loss: 0.7046, Total Time: 05 hours, 27 minutes, 36 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7259557617677225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4411, Test Loss: 0.6275, Total Time: 05 hours, 34 minutes, 19 seconds\n",
      "Epoch 2/10, Train Loss: 0.3439, Test Loss: 0.6895, Total Time: 05 hours, 34 minutes, 47 seconds\n",
      "Epoch 3/10, Train Loss: 0.2888, Test Loss: 0.4157, Total Time: 05 hours, 43 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.2428, Test Loss: 0.4163, Total Time: 05 hours, 35 minutes, 47 seconds\n",
      "Epoch 5/10, Train Loss: 0.2049, Test Loss: 0.3158, Total Time: 07 hours, 43 minutes, 43 seconds\n",
      "Epoch 6/10, Train Loss: 0.1741, Test Loss: 0.5003, Total Time: 08 hours, 44 minutes, 26 seconds\n",
      "Epoch 7/10, Train Loss: 0.1587, Test Loss: 0.3826, Total Time: 08 hours, 34 minutes, 52 seconds\n",
      "Epoch 8/10, Train Loss: 0.1292, Test Loss: 0.3596, Total Time: 08 hours, 28 minutes, 02 seconds\n",
      "Epoch 9/10, Train Loss: 0.1110, Test Loss: 0.4189, Total Time: 17 hours, 53 minutes, 29 seconds\n",
      "Epoch 10/10, Train Loss: 0.1113, Test Loss: 0.3861, Total Time: 08 hours, 27 minutes, 54 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41211051089964534"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_densenet121.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Yolov5 to extract face then using ResNet to classification the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use yoloresnet model\n",
    "import model\n",
    "reload(model)\n",
    "from model import YoloResnet\n",
    "model = YoloResnet()\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_yoloresnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
