{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "## Outline\n",
    "1. Import Library\n",
    "2. Setup pre-requisites\n",
    "3. Extract dataset to images\n",
    "4. Upload images to Azure data store\n",
    "4. Setting up Azure ML Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: torch in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.18.1)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.3.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "Collecting azureml-core\n",
      "  Using cached azureml_core-1.56.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nnvuf\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Collecting azure-mgmt-resource<=24.0.0,>=15.0.0\n",
      "  Using cached azure_mgmt_resource-23.1.1-py3-none-any.whl (2.6 MB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Using cached msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.9.0.post0)\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n",
      "  Using cached azure_mgmt_keyvault-10.3.1-py3-none-any.whl (901 kB)\n",
      "Requirement already satisfied: PyJWT<3.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.8.0)\n",
      "Collecting azure-mgmt-network<=26.0.0\n",
      "  Using cached azure_mgmt_network-25.4.0-py3-none-any.whl (614 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Using cached adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Using cached msal-1.30.0-py3-none-any.whl (111 kB)\n",
      "Collecting azure-mgmt-storage<=22.0.0,>=16.0.0\n",
      "  Using cached azure_mgmt_storage-21.2.1-py3-none-any.whl (3.2 MB)\n",
      "Collecting docker<8.0.0\n",
      "  Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Collecting paramiko<4.0.0,>=2.0.8\n",
      "  Using cached paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.1.28)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Using cached azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting jsonpickle<4.0.0\n",
      "  Using cached jsonpickle-3.2.2-py3-none-any.whl (41 kB)\n",
      "Collecting knack<0.12.0\n",
      "  Using cached knack-0.11.0-py3-none-any.whl (60 kB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Using cached SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting backports.tempfile\n",
      "  Using cached backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0\n",
      "  Using cached azure_mgmt_containerregistry-10.3.0-py3-none-any.whl (2.3 MB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Using cached ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting msrest<=0.7.1,>=0.5.1\n",
      "  Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting jmespath<2.0.0\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2024.1)\n",
      "Requirement already satisfied: packaging<=25.0,>=20.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (24.0)\n",
      "Collecting pyopenssl<25.0.0\n",
      "  Using cached pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azure-core<2.0.0\n",
      "  Using cached azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
      "Collecting argcomplete<4\n",
      "  Using cached argcomplete-3.4.0-py3-none-any.whl (42 kB)\n",
      "Collecting azure-mgmt-authorization<5,>=0.40.0\n",
      "  Using cached azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: pathspec<1.0.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (0.12.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>1.26.17 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (2.2.2)\n",
      "Collecting msal-extensions<=2.0.0,>=0.3.0\n",
      "  Using cached msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pkginfo in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azureml-core) (1.11.1)\n",
      "Collecting cryptography>=1.1.0\n",
      "  Using cached cryptography-43.0.0-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core<2.0.0->azureml-core) (1.16.0)\n",
      "Collecting isodate<1.0.0,>=0.6.1\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.3.2\n",
      "  Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\nnvuf\\appdata\\roaming\\python\\python310\\site-packages (from docker<8.0.0->azureml-core) (306)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly<11.0,>=4.7->azureml-core) (3.4.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\nnvuf\\appdata\\roaming\\python\\python310\\site-packages (from knack<0.12.0->azureml-core) (2.18.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack<0.12.0->azureml-core) (6.0.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from knack<0.12.0->azureml-core) (0.9.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core) (2.10.1)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ndg-httpsclient<=0.5.1->azureml-core) (0.6.0)\n",
      "Collecting pynacl>=1.5\n",
      "  Using cached PyNaCl-1.5.0-cp36-abi3-win_amd64.whl (212 kB)\n",
      "Collecting bcrypt>=3.2\n",
      "  Using cached bcrypt-4.1.3-cp39-abi3-win_amd64.whl (158 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (1.7.1)\n",
      "Collecting jeepney>=0.6\n",
      "  Using cached jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: backports.weakref in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from backports.tempfile->azureml-core) (1.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core) (1.16.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nnvuf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core) (2.22)\n",
      "Installing collected packages: opencv-python, oauthlib, jsonpickle, jmespath, jeepney, isodate, idna, humanfriendly, contextlib2, charset-normalizer, certifi, bcrypt, backports.tempfile, argcomplete, requests, pynacl, knack, cryptography, torchaudio, SecretStorage, requests-oauthlib, pyopenssl, paramiko, docker, azure-core, adal, ndg-httpsclient, msrest, msal, azure-mgmt-core, msrestazure, msal-extensions, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, azureml-core\n",
      "Successfully installed SecretStorage-3.3.3 adal-1.2.7 argcomplete-3.4.0 azure-core-1.30.2 azure-graphrbac-0.61.1 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-10.3.0 azure-mgmt-core-1.4.0 azure-mgmt-keyvault-10.3.1 azure-mgmt-network-25.4.0 azure-mgmt-resource-23.1.1 azure-mgmt-storage-21.2.1 azureml-core-1.56.0 backports.tempfile-1.0 bcrypt-4.1.3 certifi-2024.7.4 charset-normalizer-3.3.2 contextlib2-21.6.0 cryptography-43.0.0 docker-7.1.0 humanfriendly-10.0 idna-3.7 isodate-0.6.1 jeepney-0.8.0 jmespath-1.0.1 jsonpickle-3.2.2 knack-0.11.0 msal-1.30.0 msal-extensions-1.2.0 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.2 opencv-python-4.10.0.84 paramiko-3.4.0 pynacl-1.5.0 pyopenssl-24.2.1 requests-2.32.3 requests-oauthlib-2.0.0 torchaudio-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Install needed packages\n",
    "%pip install opencv-python torch torchvision torchaudio azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import cv2\n",
    "# from azureml.core import Workspace, Dataset, Datastore\n",
    "\n",
    "## Using torchvision to create a dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone source code from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "## curl source code from github\n",
    "!wget 'https://github.com/nnvu-fit/iusai-project/archive/refs/heads/main.zip' -O main.zip\n",
    "!unzip main.zip\n",
    "!mv iusai-project-main/* .\n",
    "!rm -rf iusai-project-main main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "ename": "UserErrorException",
     "evalue": "UserErrorException:\n\tMessage: You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \\n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \\n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Setup Azure ML Workspace\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ws \u001b[38;5;241m=\u001b[39m \u001b[43mWorkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## From workspace, get/create the default datastore\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ds \u001b[38;5;241m=\u001b[39m ws\u001b[38;5;241m.\u001b[39mget_default_datastore()\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\workspace.py:292\u001b[0m, in \u001b[0;36mWorkspace.from_config\u001b[1;34m(path, auth, _logger, _file_name)\u001b[0m\n\u001b[0;32m    288\u001b[0m subscription_id, resource_group, workspace_name \u001b[38;5;241m=\u001b[39m project_info\u001b[38;5;241m.\u001b[39mget_workspace_info(\n\u001b[0;32m    289\u001b[0m     found_path)\n\u001b[0;32m    291\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound the config file in: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, found_path)\n\u001b[1;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWorkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\workspace.py:607\u001b[0m, in \u001b[0;36mWorkspace.get\u001b[1;34m(name, auth, subscription_id, resource_group, location, cloud, id)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m auth:\n\u001b[0;32m    605\u001b[0m     auth \u001b[38;5;241m=\u001b[39m InteractiveLoginAuthentication()\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWorkspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_cloud\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcloud\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_workspace_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\workspace.py:205\u001b[0m, in \u001b[0;36mWorkspace.__init__\u001b[1;34m(self, subscription_id, resource_group, workspace_name, auth, _location, _disable_service_check, _workspace_id, sku, tags, _cloud)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_autorest_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _disable_service_check:\n\u001b[1;32m--> 205\u001b[0m     auto_rest_workspace \u001b[38;5;241m=\u001b[39m \u001b[43m_commands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_workspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_workspace_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_autorest_object \u001b[38;5;241m=\u001b[39m auto_rest_workspace\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\_project\\_commands.py:467\u001b[0m, in \u001b[0;36mget_workspace\u001b[1;34m(auth, subscription_id, resource_group_name, workspace_name, location, cloud, workspace_id)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         workspaces \u001b[38;5;241m=\u001b[39m \u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_service_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAzureMachineLearningWorkspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mworkspaces\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m WorkspacesOperations\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    471\u001b[0m             workspaces,\n\u001b[0;32m    472\u001b[0m             resource_group_name,\n\u001b[0;32m    473\u001b[0m             workspace_name)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ClientRequestError:\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;66;03m# this most likely is because of failure to talk to arm.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;66;03m# Provide error message to user if they are in synapse enviroment.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# Additional params will enable aml dataplane get workspace call. \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\authentication.py:230\u001b[0m, in \u001b[0;36mAbstractAuthentication._get_service_client\u001b[1;34m(self, client_class, subscription_id, subscription_bound, base_url, is_check_subscription)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subscription_id \u001b[38;5;129;01mand\u001b[39;00m is_check_subscription:\n\u001b[0;32m    229\u001b[0m     all_subscription_list, tenant_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_subscription_ids()\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_subscription_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_subscription_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_url:\n\u001b[0;32m    233\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_type\u001b[38;5;241m.\u001b[39mendpoints\u001b[38;5;241m.\u001b[39mresource_manager\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\authentication.py:681\u001b[0m, in \u001b[0;36mInteractiveLoginAuthentication._check_if_subscription_exists\u001b[1;34m(self, subscription_id, subscription_id_list, tenant_id)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_if_subscription_exists\u001b[39m(\u001b[38;5;28mself\u001b[39m, subscription_id, subscription_id_list, tenant_id):\n\u001b[1;32m--> 681\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mInteractiveLoginAuthentication\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_subscription_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43msubscription_id_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\azureml\\core\\authentication.py:338\u001b[0m, in \u001b[0;36mAbstractAuthentication._check_if_subscription_exists\u001b[1;34m(self, subscription_id, subscription_id_list, tenant_id)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like you have specified subscription name, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, instead of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription id. Subscription names may not be unique, please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription id from this list \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subscription_id,\n\u001b[0;32m    336\u001b[0m                                                                            subscription_id_list))\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are currently logged-in to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m tenant. You don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have access \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    339\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m subscription, please check if it is in this tenant. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    340\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll the subscriptions that you have access to in this tenant are = \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    341\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Please refer to aka.ms/aml-notebook-auth for different \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    342\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthentication mechanisms in azureml-sdk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tenant_id,\n\u001b[0;32m    343\u001b[0m                                                                                 subscription_id,\n\u001b[0;32m    344\u001b[0m                                                                                 subscription_id_list))\n",
      "\u001b[1;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"You are currently logged-in to 66bbbbf2-d789-4231-8e48-08bfeb9cba42 tenant. You don't have access to d554f489-6933-4c33-8722-a536b3682bd7 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \\n [SubscriptionInfo(subscription_name='DEKRA_Application_Subscription', subscription_id='8db25668-388f-4e79-883a-54133883a597')]. \\n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "## Setup Azure ML Workspace\n",
    "ws = Workspace.from_config()\n",
    "## From workspace, get/create the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "ws, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract dataset to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path:  videos/\n",
      "images_path:  images/\n"
     ]
    }
   ],
   "source": [
    "## define videos location + images output location\n",
    "video_path = 'videos/'\n",
    "images_path = 'images/'\n",
    "print('video_path: ', video_path)\n",
    "print('images_path: ', images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dict of videos/subject10/huangpi21.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject1/Yousef1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject11/alhashe31.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject13/guolingh1.avi (start): [['0', 0], ['6', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject12/makiluke1.avi (start): [['0', 0], ['2', 0]]\n",
      "Label dict of videos/subject14/chuangy61.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject15/bajajpak1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject16/dhingra51.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject17/zhoulian1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject18/yuqianyi1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject19/wangyus11.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dict of videos/subject21/Mark1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject23/vahid1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject22/yarub1.avi (start): [['0', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject2/Jourabloo1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject20/Cool1.avi (start): [['0', 0], ['2', 0], ['1', 0]]\n",
      "Label dict of videos/subject24/mustaffa1.avi (start): [['0', 0], ['1', 0], ['5', 0], ['2', 0]]\n",
      "Label dict of videos/subject4/meowseph1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject3/XiYin1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject5/Muath1.avi (start): [['0', 0], ['1', 0], ['2', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject6/husseinhijazi1.avi (start): [['0', 0], ['2', 0], ['1', 0], ['5', 0], ['6', 0], ['3', 0]]\n",
      "Label dict of videos/subject7/zach1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['2', 0], ['3', 0]]\n",
      "Label dict of videos/subject8/vaibhav1.avi (start): [['0', 0], ['3', 0], ['1', 0], ['2', 0]]\n",
      "Label dict of videos/subject9/chenlipi1.avi (start): [['0', 0], ['6', 0], ['1', 0], ['5', 0], ['3', 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10 (extract_images_from_videos):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nnvuf\\source\\ai-final-project\\v2i.py\", line 67, in extract_images_from_videos\n",
      "    cv2.destroyAllWindows()\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import v2i\n",
    "reload(v2i)\n",
    "from v2i import extract_images_from_videos\n",
    "import threading\n",
    "\n",
    "def extract_images_from_videos_collection(video_path, images_path):\n",
    "    ## get all videos file in video_path\n",
    "    video_list_location_collection = os.listdir(video_path)\n",
    "\n",
    "    ## define total_label_dict\n",
    "    ## create threading pool\n",
    "    thread = []\n",
    "    ## for each video file\n",
    "    for video_list_location in video_list_location_collection:\n",
    "        ## check if video_location is not a directory (i.e. is a file), then skip\n",
    "        if not os.path.isdir(video_path + video_list_location):\n",
    "            continue\n",
    "        ## list videos in video_location\n",
    "        thread.append(threading.Thread(target=extract_images_from_videos, args=(video_path + video_list_location, images_path, 24)))\n",
    "        # extract_images_from_videos(video_path + video_list_location, images_path, inteval=1)\n",
    "\n",
    "    ## start all threads\n",
    "    for t in thread: t.start()\n",
    "    ## wait for all threads to finish\n",
    "    for t in thread:\n",
    "        t.join()\n",
    "    \n",
    "    ## check images in images_path\n",
    "    images_list_location_collection = os.listdir(images_path)\n",
    "    print('images_list_location_collection: ', images_list_location_collection)\n",
    "\n",
    "# video_subject_6_path = video_path + '/subject6-###'\n",
    "# ## list videos in video_location\n",
    "# label_dict = extract_images_from_videos(video_subject_6_path, images_path)\n",
    "\n",
    "## extract images from videos\n",
    "extract_images_from_videos_collection(video_path, images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Upload images to Azure data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from 'c:/Users/nnvuf/source/ai-final-project/images' to 'images-extra-small'\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', '/images-extra-small')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"22c174ee-e3e7-4e60-a949-e20eb237c73d\",\n",
       "    \"name\": \"images-extra-small\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"images-extra-small\",\n",
       "    \"workspace\": \"Workspace.create(name='ws-vunn-iusai-sea-sp6k7', subscription_id='d554f489-6933-4c33-8722-a536b3682bd7', resource_group='rg-vunn-iusai-sea-sp6k7')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## upload images to data asset using Dataset.File.upload_directory\n",
    "Dataset.File.upload_directory(src_dir=images_path, target=(ds, 'images-extra-small'), overwrite=True, show_progress=True) \\\n",
    "    .register(workspace=ws, name='images-extra-small', description='images-extra-small') ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setup public workspace endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_collection:  images-extra-small  is already registered\n",
      "dataset_collection:  images-small-v2  is already registered\n",
      "dataset_collection:  images-medium  is already registered\n"
     ]
    }
   ],
   "source": [
    "dataset_collection_list = ['images-extra-small', 'images-small-v2', 'images-medium']\n",
    "## register dataset using Dataset.File.from_files\n",
    "for dataset_collection in dataset_collection_list:\n",
    "    ## check if dataset_collection is already registered\n",
    "    if dataset_collection in ws.datasets.keys():\n",
    "        print('dataset_collection: ', dataset_collection, ' is already registered')\n",
    "        continue\n",
    "    Dataset.File.from_files(path=(ds, dataset_collection)) \\\n",
    "        .register(workspace=ws, name=dataset_collection, description=dataset_collection) ## register dataset \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train models\n",
    "1. ResNET\n",
    "2. DenseNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup device + load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import train and scrore function from train.py\n",
    "import train as t;\n",
    "reload(t)\n",
    "from train import cross_validate, score_model, get_device\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "images_path = 'images'\n",
    "images_ds_path = \"images-extra-small\"\n",
    "if not os.path.exists(images_path):\n",
    "    os.mkdir(images_path)\n",
    "# download data asset to local if images_path is empty\n",
    "if len(os.listdir(images_path)) == 0:\n",
    "    print('images_path is empty, download images_ds to images_path')\n",
    "    # download data asset to local\n",
    "    images_ds = Dataset.get_by_name(workspace=ws, name=images_ds_path)\n",
    "    images_ds.download(target_path=images_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import data_set as ds\n",
    "reload(ds)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "imageDataset = ds.ImageDataset('images-small', transform=transform)\n",
    "## define batch_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  [0, 1, 2, 3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "image, label = imageDataset.get_image(0)\n",
    "# image.show()\n",
    "labels = imageDataset.labels()\n",
    "## show labels in Interger\n",
    "print('labels: ',  [int(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds:  37715\n",
      "val_ds:  9429\n",
      "test_ds:  5239\n"
     ]
    }
   ],
   "source": [
    "## split dataset into train and test dataset using random_split\n",
    "from torch.utils.data import random_split\n",
    "train_val_size = int(0.9 * len(imageDataset))\n",
    "test_size = len(imageDataset) - train_val_size\n",
    "train_val_ds, test_ds = random_split(imageDataset, [train_val_size, test_size])\n",
    "\n",
    "## split train_val_ds into train_ds and val_ds using random_split\n",
    "train_size = int(0.8 * len(train_val_ds))\n",
    "val_size = len(train_val_ds) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_val_ds, [train_size, val_size])\n",
    "\n",
    "print('train_ds: ', len(train_ds))\n",
    "print('val_ds: ', len(val_ds))\n",
    "print('test_ds: ', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnes18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "module cross_validate not in sys.modules",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_validate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m cross_validate(model, optimizer, loss_fn, train_val_ds, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m## score model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:148\u001b[0m, in \u001b[0;36mreload\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mget(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module:\n\u001b[0;32m    147\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not in sys.modules\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name), name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _RELOADING:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _RELOADING[name]\n",
      "\u001b[1;31mImportError\u001b[0m: module cross_validate not in sys.modules"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "cross_validate(model, optimizer, loss_fn, train_val_ds, epochs=5, device=device)\n",
    "## score model\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes18.100_epochs.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnes34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.resnet34(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes34.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## get resnet model of image classification from torchvision\n",
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\notebook.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## train model\u001b[39;00m\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## score model\u001b[39;00m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nnvuf/source/ai-final-project/notebook.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m score_model(model, loss_fn, test_dataloader, device\u001b[39m=\u001b[39mdevice)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\source\\ai-final-project\\train.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, train_dataset, test_dataset, epochs, device)\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m   loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;32m     34\u001b[0m   optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m---> 35\u001b[0m   train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;32m     36\u001b[0m train_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataset\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[0;32m     37\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train model\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4070, Test Loss: 0.4468, Total Time: 00 hours, 10 minutes, 50 seconds\n",
      "Epoch 2/10, Train Loss: 0.2953, Test Loss: 0.3624, Total Time: 00 hours, 12 minutes, 53 seconds\n",
      "Epoch 3/10, Train Loss: 0.2196, Test Loss: 0.3772, Total Time: 00 hours, 13 minutes, 49 seconds\n",
      "Epoch 4/10, Train Loss: 0.1600, Test Loss: 0.3560, Total Time: 00 hours, 16 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.1331, Test Loss: 0.3690, Total Time: 00 hours, 15 minutes, 54 seconds\n",
      "Epoch 6/10, Train Loss: 0.1037, Test Loss: 0.3158, Total Time: 00 hours, 15 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0790, Test Loss: 0.3453, Total Time: 00 hours, 15 minutes, 53 seconds\n",
      "Epoch 8/10, Train Loss: 0.0761, Test Loss: 0.4047, Total Time: 00 hours, 15 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0618, Test Loss: 0.3804, Total Time: 00 hours, 15 minutes, 21 seconds\n",
      "Epoch 10/10, Train Loss: 0.0561, Test Loss: 0.4284, Total Time: 00 hours, 16 minutes, 02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4667215104080109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=100, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_resnes18.100_epochs.small.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get denseNet model of image classification from torchvision\n",
    "model = torchvision.models.densenet121(pretrained=True, num_classes=len(labels))\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.6834, Test Loss: 0.7046, Total Time: 05 hours, 27 minutes, 36 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7259557617677225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4411, Test Loss: 0.6275, Total Time: 05 hours, 34 minutes, 19 seconds\n",
      "Epoch 2/10, Train Loss: 0.3439, Test Loss: 0.6895, Total Time: 05 hours, 34 minutes, 47 seconds\n",
      "Epoch 3/10, Train Loss: 0.2888, Test Loss: 0.4157, Total Time: 05 hours, 43 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.2428, Test Loss: 0.4163, Total Time: 05 hours, 35 minutes, 47 seconds\n",
      "Epoch 5/10, Train Loss: 0.2049, Test Loss: 0.3158, Total Time: 07 hours, 43 minutes, 43 seconds\n",
      "Epoch 6/10, Train Loss: 0.1741, Test Loss: 0.5003, Total Time: 08 hours, 44 minutes, 26 seconds\n",
      "Epoch 7/10, Train Loss: 0.1587, Test Loss: 0.3826, Total Time: 08 hours, 34 minutes, 52 seconds\n",
      "Epoch 8/10, Train Loss: 0.1292, Test Loss: 0.3596, Total Time: 08 hours, 28 minutes, 02 seconds\n",
      "Epoch 9/10, Train Loss: 0.1110, Test Loss: 0.4189, Total Time: 17 hours, 53 minutes, 29 seconds\n",
      "Epoch 10/10, Train Loss: 0.1113, Test Loss: 0.3861, Total Time: 08 hours, 27 minutes, 54 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41211051089964534"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_densenet121.small.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Yolov5 to extract face then using ResNet to classification the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use yoloresnet model\n",
    "import model\n",
    "reload(model)\n",
    "from model import YoloResnet\n",
    "model = YoloResnet()\n",
    "## define optimizer using Adam and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 1 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=1, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using device (CPU or GPU) 10 epoch\n",
    "train(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs=10, device=device)\n",
    "## score model\n",
    "score_model(model, loss_fn, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), 'model_yoloresnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
