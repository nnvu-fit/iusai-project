{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c98c9f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f0af9de",
   "metadata": {},
   "source": [
    "# Inport needed package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2073d",
   "metadata": {},
   "source": [
    "- import os, sys # to add the parent directory to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6f3365",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0bf9d",
   "metadata": {},
   "source": [
    "- Using torchvision to create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84577080",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Using torchvision to create a dataset\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353412ad",
   "metadata": {},
   "source": [
    "- import self library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec759ec",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from train.trainer import ClassifierTrainer as Trainer\n",
    "import dataset as ds  # type: ignore\n",
    "import model as md  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec973ee2",
   "metadata": {},
   "source": [
    "# Define classification train process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872305b",
   "metadata": {},
   "source": [
    "1. Define place where the model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65f0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d88245",
   "metadata": {},
   "source": [
    "2. Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554ddc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTheTrain(dataset, model):\n",
    "  # define batch_size\n",
    "  batch_size = 64\n",
    "\n",
    "  # init train val test ds\n",
    "  train_val_size = int(0.8 * len(dataset))\n",
    "  test_size = len(dataset) - train_val_size\n",
    "  train_ds, test_ds = random_split(dataset, [train_val_size, test_size])\n",
    "\n",
    "  # define optimizer using Adam and loss function\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "  loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  trainer = Trainer(model, optimizer, loss_fn, random_seed_value=86)\n",
    "  print('device: ', trainer.device)\n",
    "  avg_loss, metric = trainer.cross_validate(train_ds, k=5, epochs=10, batch_size=batch_size)\n",
    "  print('avg_loss: ', avg_loss)\n",
    "\n",
    "  # score model\n",
    "  test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "  model_scored = trainer.score(test_dataloader)\n",
    "  print(f'model_scored: {model_scored:.4f}, avg_accuracy: {100*(1 - model_scored):.4f}')\n",
    "\n",
    "  # return model scored, train_avg_lost\n",
    "  return model_scored, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e26c06",
   "metadata": {},
   "source": [
    "3. execute progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bbab88",
   "metadata": {},
   "source": [
    "- define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2317e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\ttorchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT),\n",
    "  torchvision.models.densenet121(weights=torchvision.models.DenseNet121_Weights.DEFAULT),\n",
    "  torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5733d5",
   "metadata": {},
   "source": [
    "- Define tested datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a4d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'gi4e_full': ds.Gi4eDataset(\n",
    "        './datasets/gi4e',\n",
    "        transform=transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()]),\n",
    "        is_classification=True),\n",
    "    'gi4e_raw_eyes': ds.ImageDataset(\n",
    "        './datasets/gi4e_raw_eyes',\n",
    "        transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]),\n",
    "        file_extension='png'),\n",
    "    'gi4e_detected_eyes': ds.ImageDataset(\n",
    "        './datasets/gi4e_eyes/20250521_200316',\n",
    "        transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]),\n",
    "        file_extension='png'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28afcf22",
   "metadata": {},
   "source": [
    "- Train all defined model on each registered datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1784fdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gi4e_full dataset with ResNet\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 2.3362, Test Loss: 0.4823, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 2/10, Train Loss: 0.0202, Test Loss: 0.0091, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 3/10, Train Loss: 0.0013, Test Loss: 0.0004, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 4/10, Train Loss: 0.0003, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 5/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 6/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Fold 1/5, Total Test Loss: 0.0000, Fold accuracy: 99.9983\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 2/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 2/5, Total Test Loss: 0.0000, Fold accuracy: 99.9995\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Fold 3/5, Total Test Loss: 0.0000, Fold accuracy: 99.9998\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Fold 4/5, Total Test Loss: 0.0000, Fold accuracy: 99.9998\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 38 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 54 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 53 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 56 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 36 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 59 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 01 minutes, 00 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 43 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 47 seconds\n",
      "Fold 5/5, Total Test Loss: 0.0000, Fold accuracy: 99.9999\n",
      "avg_loss:  5.449964180455115e-06\n",
      "model_scored: 0.0000, avg_accuracy: 99.9994\n",
      "Finished gi4e_full dataset with ResNet\n",
      "----------------------\n",
      "Running gi4e_full dataset with DenseNet\n",
      "device:  cuda\n",
      "Fold 1/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnvuf\\AppData\\Local\\Temp\\ipykernel_28364\\3706550783.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.0503, Test Loss: 2.0258, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 2/10, Train Loss: 0.0292, Test Loss: 0.0757, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0050, Test Loss: 0.0045, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 4/10, Train Loss: 0.0018, Test Loss: 0.0013, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 5/10, Train Loss: 0.0009, Test Loss: 0.0008, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 6/10, Train Loss: 0.0006, Test Loss: 0.0006, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 7/10, Train Loss: 0.0005, Test Loss: 0.0005, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 8/10, Train Loss: 0.0003, Test Loss: 0.0004, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 9/10, Train Loss: 0.0003, Test Loss: 0.0004, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 10/10, Train Loss: 0.0002, Test Loss: 0.0003, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Fold 1/5, Total Test Loss: 0.0003, Fold accuracy: 99.9670\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.0003, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 2/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 3/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 4/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 5/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 6/10, Train Loss: 0.0001, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 2/5, Total Test Loss: 0.0004, Fold accuracy: 99.9955\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 2/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 4/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 5/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 6/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 3/5, Total Test Loss: 0.0004, Fold accuracy: 99.9972\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 2/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 4/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 5/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 4/5, Total Test Loss: 0.0004, Fold accuracy: 99.9982\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 5/5, Total Test Loss: 0.0004, Fold accuracy: 99.9987\n",
      "avg_loss:  8.70754880867801e-05\n",
      "model_scored: 0.0001, avg_accuracy: 99.9950\n",
      "Finished gi4e_full dataset with DenseNet\n",
      "----------------------\n",
      "Running gi4e_full dataset with VGG\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 10.9852, Test Loss: 5.2628, Total Time: 00 hours, 00 minutes, 32 seconds\n",
      "Epoch 2/10, Train Loss: 4.9492, Test Loss: 4.7604, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 3/10, Train Loss: 4.5277, Test Loss: 4.2379, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 4/10, Train Loss: 3.7312, Test Loss: 3.3256, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 5/10, Train Loss: 2.9509, Test Loss: 2.4405, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 6/10, Train Loss: 1.9448, Test Loss: 1.0745, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 1.0565, Test Loss: 0.5585, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 8/10, Train Loss: 0.6724, Test Loss: 0.2326, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 9/10, Train Loss: 0.3953, Test Loss: 0.1549, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 10/10, Train Loss: 0.2336, Test Loss: 0.1197, Total Time: 00 hours, 00 minutes, 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Total Test Loss: 0.1197, Fold accuracy: 88.0342\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.1992, Test Loss: 0.0240, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 2/10, Train Loss: 0.1017, Test Loss: 0.0180, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 3/10, Train Loss: 0.1340, Test Loss: 0.0392, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 4/10, Train Loss: 0.1911, Test Loss: 0.0413, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 5/10, Train Loss: 0.0867, Test Loss: 0.0011, Total Time: 00 hours, 00 minutes, 28 seconds\n",
      "Epoch 6/10, Train Loss: 0.0436, Test Loss: 0.0079, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 0.0568, Test Loss: 0.0022, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 8/10, Train Loss: 0.0312, Test Loss: 0.0072, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 9/10, Train Loss: 0.0217, Test Loss: 0.0091, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 10/10, Train Loss: 0.0873, Test Loss: 0.0020, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Fold 2/5, Total Test Loss: 0.1216, Fold accuracy: 99.8037\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0335, Test Loss: 0.0006, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 2/10, Train Loss: 0.0695, Test Loss: 0.0120, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 3/10, Train Loss: 0.0861, Test Loss: 0.0192, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 4/10, Train Loss: 0.0449, Test Loss: 0.0103, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 5/10, Train Loss: 0.0875, Test Loss: 0.1461, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 6/10, Train Loss: 0.1212, Test Loss: 0.0035, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 0.0274, Test Loss: 0.0399, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 8/10, Train Loss: 0.0562, Test Loss: 0.0866, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 9/10, Train Loss: 0.0526, Test Loss: 0.0049, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 10/10, Train Loss: 0.0428, Test Loss: 0.0035, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Fold 3/5, Total Test Loss: 0.1251, Fold accuracy: 99.6495\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0313, Test Loss: 0.0087, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 2/10, Train Loss: 0.0100, Test Loss: 0.0050, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 3/10, Train Loss: 0.0405, Test Loss: 0.2224, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 4/10, Train Loss: 0.1876, Test Loss: 0.1319, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 5/10, Train Loss: 0.1115, Test Loss: 0.0103, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 6/10, Train Loss: 0.0740, Test Loss: 0.0208, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 0.0260, Test Loss: 0.0009, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 8/10, Train Loss: 0.0129, Test Loss: 0.0076, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 9/10, Train Loss: 0.0855, Test Loss: 0.2452, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 10/10, Train Loss: 0.0759, Test Loss: 0.0818, Total Time: 00 hours, 00 minutes, 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Total Test Loss: 0.2070, Fold accuracy: 91.8152\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.1425, Test Loss: 0.0374, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 2/10, Train Loss: 0.0307, Test Loss: 0.0004, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 3/10, Train Loss: 0.0146, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 4/10, Train Loss: 0.0376, Test Loss: 0.0028, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 5/10, Train Loss: 0.0240, Test Loss: 0.0002, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 6/10, Train Loss: 0.0731, Test Loss: 0.8355, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 0.1632, Test Loss: 0.0188, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 8/10, Train Loss: 0.0663, Test Loss: 0.1087, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 9/10, Train Loss: 0.0906, Test Loss: 0.0188, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 10/10, Train Loss: 0.1689, Test Loss: 0.0630, Total Time: 00 hours, 00 minutes, 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Total Test Loss: 0.2699, Fold accuracy: 93.7036\n",
      "avg_loss:  0.05398754474810659\n",
      "model_scored: 0.1178, avg_accuracy: 88.2191\n",
      "Finished gi4e_full dataset with VGG\n",
      "----------------------\n",
      "Running gi4e_raw_eyes dataset with ResNet\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 2.1701, Test Loss: 4.0340, Total Time: 00 hours, 00 minutes, 28 seconds\n",
      "Epoch 2/10, Train Loss: 0.1522, Test Loss: 0.3019, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 3/10, Train Loss: 0.0469, Test Loss: 0.2338, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 4/10, Train Loss: 0.0331, Test Loss: 0.2223, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.0417, Test Loss: 0.2637, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 6/10, Train Loss: 0.0234, Test Loss: 0.1619, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 7/10, Train Loss: 0.0227, Test Loss: 0.3744, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 8/10, Train Loss: 0.0287, Test Loss: 0.2528, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 9/10, Train Loss: 0.0426, Test Loss: 0.5159, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 10/10, Train Loss: 0.0693, Test Loss: 0.8067, Total Time: 00 hours, 00 minutes, 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Total Test Loss: 0.8067, Fold accuracy: 19.3323\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.0983, Test Loss: 0.4577, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 2/10, Train Loss: 0.0437, Test Loss: 0.0659, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 3/10, Train Loss: 0.0460, Test Loss: 0.0793, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 4/10, Train Loss: 0.0197, Test Loss: 0.0357, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.0301, Test Loss: 0.2418, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 6/10, Train Loss: 0.0055, Test Loss: 0.0163, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 7/10, Train Loss: 0.0009, Test Loss: 0.0105, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 8/10, Train Loss: 0.0004, Test Loss: 0.0083, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 9/10, Train Loss: 0.0002, Test Loss: 0.0080, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0089, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Fold 2/5, Total Test Loss: 0.8155, Fold accuracy: 99.1133\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0010, Test Loss: 0.0095, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 2/10, Train Loss: 0.0058, Test Loss: 0.0077, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 3/10, Train Loss: 0.0071, Test Loss: 0.0025, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 4/10, Train Loss: 0.0035, Test Loss: 0.0090, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.0064, Test Loss: 0.0065, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 6/10, Train Loss: 0.0693, Test Loss: 0.3673, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 7/10, Train Loss: 0.0677, Test Loss: 0.9849, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 8/10, Train Loss: 0.0710, Test Loss: 0.2892, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 9/10, Train Loss: 0.0730, Test Loss: 0.5266, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 10/10, Train Loss: 0.0544, Test Loss: 0.1723, Total Time: 00 hours, 00 minutes, 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Total Test Loss: 0.9879, Fold accuracy: 82.7681\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0353, Test Loss: 0.0695, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 2/10, Train Loss: 0.0395, Test Loss: 0.0405, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 3/10, Train Loss: 0.0222, Test Loss: 0.0145, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 4/10, Train Loss: 0.0116, Test Loss: 0.0081, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.0020, Test Loss: 0.0041, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 6/10, Train Loss: 0.0119, Test Loss: 0.0583, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 7/10, Train Loss: 0.0142, Test Loss: 0.0406, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 8/10, Train Loss: 0.0074, Test Loss: 0.0022, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 9/10, Train Loss: 0.0005, Test Loss: 0.0004, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 10/10, Train Loss: 0.0003, Test Loss: 0.0002, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Fold 4/5, Total Test Loss: 0.9880, Fold accuracy: 99.9828\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0003, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 2/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 3/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 4/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 5/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 6/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 10 seconds\n",
      "Fold 5/5, Total Test Loss: 0.9880, Fold accuracy: 99.9987\n",
      "avg_loss:  0.19760944515428283\n",
      "model_scored: 0.0593, avg_accuracy: 94.0685\n",
      "Finished gi4e_raw_eyes dataset with ResNet\n",
      "----------------------\n",
      "Running gi4e_raw_eyes dataset with DenseNet\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 1.9391, Test Loss: 2.4509, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 2/10, Train Loss: 0.1147, Test Loss: 0.1790, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 3/10, Train Loss: 0.0402, Test Loss: 0.1435, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 4/10, Train Loss: 0.0159, Test Loss: 0.0591, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 5/10, Train Loss: 0.0039, Test Loss: 0.0593, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 6/10, Train Loss: 0.0014, Test Loss: 0.0533, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 7/10, Train Loss: 0.0010, Test Loss: 0.0499, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 8/10, Train Loss: 0.0009, Test Loss: 0.0478, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 9/10, Train Loss: 0.0007, Test Loss: 0.0476, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 10/10, Train Loss: 0.0006, Test Loss: 0.0461, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Fold 1/5, Total Test Loss: 0.0461, Fold accuracy: 95.3864\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.0209, Test Loss: 0.0644, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 2/10, Train Loss: 0.0330, Test Loss: 0.3305, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 3/10, Train Loss: 0.0353, Test Loss: 0.1393, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 4/10, Train Loss: 0.0946, Test Loss: 0.3578, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 5/10, Train Loss: 0.0534, Test Loss: 0.2844, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 6/10, Train Loss: 0.0388, Test Loss: 0.0596, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 7/10, Train Loss: 0.0039, Test Loss: 0.0067, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 8/10, Train Loss: 0.0010, Test Loss: 0.0031, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 9/10, Train Loss: 0.0006, Test Loss: 0.0027, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 10/10, Train Loss: 0.0004, Test Loss: 0.0032, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Fold 2/5, Total Test Loss: 0.0493, Fold accuracy: 99.6817\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0015, Test Loss: 0.0007, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 2/10, Train Loss: 0.0065, Test Loss: 0.0247, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 3/10, Train Loss: 0.0122, Test Loss: 0.1943, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 4/10, Train Loss: 0.0190, Test Loss: 0.4222, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 5/10, Train Loss: 0.0793, Test Loss: 0.6630, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 6/10, Train Loss: 0.0824, Test Loss: 1.5058, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 7/10, Train Loss: 0.0491, Test Loss: 0.0491, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 8/10, Train Loss: 0.0072, Test Loss: 0.0256, Total Time: 00 hours, 00 minutes, 12 seconds\n",
      "Epoch 9/10, Train Loss: 0.0065, Test Loss: 0.0216, Total Time: 00 hours, 00 minutes, 13 seconds\n",
      "Epoch 10/10, Train Loss: 0.0030, Test Loss: 0.0240, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 3/5, Total Test Loss: 0.0733, Fold accuracy: 97.5990\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0072, Test Loss: 0.0003, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 2/10, Train Loss: 0.0009, Test Loss: 0.0002, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0004, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.0004, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 5/10, Train Loss: 0.0003, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 6/10, Train Loss: 0.0003, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 7/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 8/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 9/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 10/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Fold 4/5, Total Test Loss: 0.0734, Fold accuracy: 99.9941\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0002, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 2/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 4/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 5/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 6/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 20 seconds\n",
      "Fold 5/5, Total Test Loss: 0.0734, Fold accuracy: 99.9975\n",
      "avg_loss:  0.0146826217307074\n",
      "model_scored: 0.0146, avg_accuracy: 98.5449\n",
      "Finished gi4e_raw_eyes dataset with DenseNet\n",
      "----------------------\n",
      "Running gi4e_raw_eyes dataset with VGG\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 5.7432, Test Loss: 4.4216, Total Time: 00 hours, 00 minutes, 30 seconds\n",
      "Epoch 2/10, Train Loss: 4.1902, Test Loss: 3.7638, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 3/10, Train Loss: 3.3359, Test Loss: 2.8862, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 4/10, Train Loss: 2.3494, Test Loss: 1.7422, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 5/10, Train Loss: 1.5447, Test Loss: 1.4785, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 6/10, Train Loss: 1.0387, Test Loss: 0.7936, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 7/10, Train Loss: 0.7270, Test Loss: 0.5462, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 8/10, Train Loss: 0.5404, Test Loss: 0.6545, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 9/10, Train Loss: 0.5080, Test Loss: 0.5283, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 10/10, Train Loss: 0.3302, Test Loss: 0.3777, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Fold 1/5, Total Test Loss: 0.3777, Fold accuracy: 62.2297\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.3133, Test Loss: 0.2276, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 2/10, Train Loss: 0.2497, Test Loss: 0.1769, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 3/10, Train Loss: 0.2240, Test Loss: 0.4516, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 4/10, Train Loss: 0.3204, Test Loss: 0.2283, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 5/10, Train Loss: 0.2097, Test Loss: 0.2030, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 6/10, Train Loss: 0.3510, Test Loss: 0.4855, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 7/10, Train Loss: 0.1845, Test Loss: 0.1843, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 8/10, Train Loss: 0.1341, Test Loss: 0.2005, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 9/10, Train Loss: 0.1492, Test Loss: 0.3297, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 10/10, Train Loss: 0.1020, Test Loss: 0.2836, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Fold 2/5, Total Test Loss: 0.6613, Fold accuracy: 71.6432\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.1435, Test Loss: 0.0844, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 2/10, Train Loss: 0.0667, Test Loss: 0.0865, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 3/10, Train Loss: 0.1278, Test Loss: 0.2013, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 4/10, Train Loss: 0.1091, Test Loss: 0.1248, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 5/10, Train Loss: 0.0961, Test Loss: 0.0775, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 6/10, Train Loss: 0.0918, Test Loss: 0.0767, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 7/10, Train Loss: 0.0823, Test Loss: 0.0722, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 8/10, Train Loss: 0.0706, Test Loss: 0.0448, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 9/10, Train Loss: 0.0458, Test Loss: 0.2507, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 10/10, Train Loss: 0.1494, Test Loss: 0.1866, Total Time: 00 hours, 00 minutes, 23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Total Test Loss: 0.8479, Fold accuracy: 81.3369\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.1529, Test Loss: 0.0261, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 2/10, Train Loss: 0.1323, Test Loss: 0.0409, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 3/10, Train Loss: 0.1591, Test Loss: 0.0661, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 4/10, Train Loss: 0.1887, Test Loss: 0.0310, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 5/10, Train Loss: 0.1138, Test Loss: 0.0568, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 6/10, Train Loss: 0.0590, Test Loss: 0.0099, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 7/10, Train Loss: 0.0713, Test Loss: 0.0184, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 8/10, Train Loss: 0.0631, Test Loss: 0.0253, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 9/10, Train Loss: 0.0744, Test Loss: 0.0527, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 10/10, Train Loss: 0.1013, Test Loss: 0.0342, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Fold 4/5, Total Test Loss: 0.8821, Fold accuracy: 96.5801\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0523, Test Loss: 0.0676, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 2/10, Train Loss: 0.0926, Test Loss: 0.0371, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 3/10, Train Loss: 0.3000, Test Loss: 0.0829, Total Time: 00 hours, 00 minutes, 21 seconds\n",
      "Epoch 4/10, Train Loss: 0.1745, Test Loss: 0.0278, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 5/10, Train Loss: 0.0623, Test Loss: 0.0104, Total Time: 00 hours, 00 minutes, 24 seconds\n",
      "Epoch 6/10, Train Loss: 0.0849, Test Loss: 0.1014, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 7/10, Train Loss: 0.0941, Test Loss: 0.1029, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 8/10, Train Loss: 0.0701, Test Loss: 0.0590, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 9/10, Train Loss: 0.0416, Test Loss: 0.0255, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Epoch 10/10, Train Loss: 0.0530, Test Loss: 0.0832, Total Time: 00 hours, 00 minutes, 23 seconds\n",
      "Fold 5/5, Total Test Loss: 0.9653, Fold accuracy: 91.6831\n",
      "avg_loss:  0.19305399281460822\n",
      "model_scored: 0.3980, avg_accuracy: 60.2024\n",
      "Finished gi4e_raw_eyes dataset with VGG\n",
      "----------------------\n",
      "Running gi4e_detected_eyes dataset with ResNet\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 0.0651, Test Loss: 2.9979, Total Time: 00 hours, 00 minutes, 44 seconds\n",
      "Epoch 2/10, Train Loss: 0.0559, Test Loss: 0.2576, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 3/10, Train Loss: 0.0295, Test Loss: 0.1632, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 4/10, Train Loss: 0.0216, Test Loss: 0.0569, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0424, Test Loss: 0.3617, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 6/10, Train Loss: 0.0192, Test Loss: 0.0770, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0195, Test Loss: 0.0698, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 8/10, Train Loss: 0.0091, Test Loss: 0.0330, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0120, Test Loss: 0.0304, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 10/10, Train Loss: 0.0042, Test Loss: 0.0089, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Fold 1/5, Total Test Loss: 0.0089, Fold accuracy: 99.1106\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.0043, Test Loss: 0.0584, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 2/10, Train Loss: 0.0095, Test Loss: 0.0026, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 3/10, Train Loss: 0.0018, Test Loss: 0.0019, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 4/10, Train Loss: 0.0015, Test Loss: 0.0014, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 5/10, Train Loss: 0.0005, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 6/10, Train Loss: 0.0002, Test Loss: 0.0002, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Fold 2/5, Total Test Loss: 0.0090, Fold accuracy: 99.9931\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 3/5, Total Test Loss: 0.0090, Fold accuracy: 99.9996\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Fold 4/5, Total Test Loss: 0.0090, Fold accuracy: 99.9998\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 2/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 3/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 4/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 6/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 15 seconds\n",
      "Epoch 7/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 14 seconds\n",
      "Epoch 8/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 14 seconds\n",
      "Epoch 10/10, Train Loss: 0.0000, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 5/5, Total Test Loss: 0.0090, Fold accuracy: 99.9999\n",
      "avg_loss:  0.0017939841402666464\n",
      "model_scored: 0.0004, avg_accuracy: 99.9580\n",
      "Finished gi4e_detected_eyes dataset with ResNet\n",
      "----------------------\n",
      "Running gi4e_detected_eyes dataset with DenseNet\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 0.0977, Test Loss: 0.5487, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 2/10, Train Loss: 0.0357, Test Loss: 0.1194, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0183, Test Loss: 0.0156, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 4/10, Train Loss: 0.0197, Test Loss: 0.1303, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0210, Test Loss: 0.4030, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 6/10, Train Loss: 0.0277, Test Loss: 0.1521, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 7/10, Train Loss: 0.0188, Test Loss: 0.2034, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 8/10, Train Loss: 0.0283, Test Loss: 0.0466, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 9/10, Train Loss: 0.0303, Test Loss: 0.1225, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 10/10, Train Loss: 0.0105, Test Loss: 0.5704, Total Time: 00 hours, 00 minutes, 18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Total Test Loss: 0.5704, Fold accuracy: 42.9605\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.0329, Test Loss: 0.2599, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 2/10, Train Loss: 0.0451, Test Loss: 0.7276, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 3/10, Train Loss: 0.0125, Test Loss: 0.0475, Total Time: 00 hours, 00 minutes, 13 seconds\n",
      "Epoch 4/10, Train Loss: 0.0076, Test Loss: 0.0236, Total Time: 00 hours, 00 minutes, 14 seconds\n",
      "Epoch 5/10, Train Loss: 0.0014, Test Loss: 0.0226, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 6/10, Train Loss: 0.0008, Test Loss: 0.0024, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 7/10, Train Loss: 0.0002, Test Loss: 0.0017, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0002, Test Loss: 0.0017, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.0002, Test Loss: 0.0016, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0018, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 2/5, Total Test Loss: 0.5722, Fold accuracy: 99.8163\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.0045, Test Loss: 0.0007, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 2/10, Train Loss: 0.0093, Test Loss: 0.3040, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 3/10, Train Loss: 0.0475, Test Loss: 0.1172, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.0759, Test Loss: 0.1735, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 5/10, Train Loss: 0.0555, Test Loss: 1.1337, Total Time: 00 hours, 00 minutes, 17 seconds\n",
      "Epoch 6/10, Train Loss: 0.0647, Test Loss: 0.5553, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 7/10, Train Loss: 0.0407, Test Loss: 0.0710, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 8/10, Train Loss: 0.0050, Test Loss: 0.0042, Total Time: 00 hours, 00 minutes, 18 seconds\n",
      "Epoch 9/10, Train Loss: 0.0009, Test Loss: 0.0024, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Epoch 10/10, Train Loss: 0.0003, Test Loss: 0.0016, Total Time: 00 hours, 00 minutes, 19 seconds\n",
      "Fold 3/5, Total Test Loss: 0.5739, Fold accuracy: 99.8378\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0010, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 2/10, Train Loss: 0.0004, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 14 seconds\n",
      "Epoch 3/10, Train Loss: 0.0003, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 4/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 5/10, Train Loss: 0.0001, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 6/10, Train Loss: 0.0002, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Fold 4/5, Total Test Loss: 0.5739, Fold accuracy: 99.9964\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 2/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 3/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 4/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 5/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 6/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 7/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 8/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 9/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Epoch 10/10, Train Loss: 0.0001, Test Loss: 0.0000, Total Time: 00 hours, 00 minutes, 11 seconds\n",
      "Fold 5/5, Total Test Loss: 0.5739, Fold accuracy: 99.9980\n",
      "avg_loss:  0.11478191392070494\n",
      "model_scored: 0.0045, avg_accuracy: 99.5527\n",
      "Finished gi4e_detected_eyes dataset with DenseNet\n",
      "----------------------\n",
      "Running gi4e_detected_eyes dataset with VGG\n",
      "device:  cuda\n",
      "Fold 1/5:\n",
      "Epoch 1/10, Train Loss: 0.2726, Test Loss: 0.0689, Total Time: 00 hours, 00 minutes, 22 seconds\n",
      "Epoch 2/10, Train Loss: 0.0725, Test Loss: 0.1210, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0570, Test Loss: 0.0973, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.0958, Test Loss: 0.1533, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0832, Test Loss: 0.0624, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 6/10, Train Loss: 0.0499, Test Loss: 0.0546, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 7/10, Train Loss: 0.0949, Test Loss: 0.0958, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0719, Test Loss: 0.1274, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.0835, Test Loss: 0.0890, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.0507, Test Loss: 0.1121, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 1/5, Total Test Loss: 0.1121, Fold accuracy: 88.7940\n",
      "Fold 2/5:\n",
      "Epoch 1/10, Train Loss: 0.2120, Test Loss: 0.0357, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 2/10, Train Loss: 0.0866, Test Loss: 0.0075, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0863, Test Loss: 0.0448, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.0591, Test Loss: 0.0289, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0688, Test Loss: 0.0183, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 6/10, Train Loss: 0.0611, Test Loss: 0.0467, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 7/10, Train Loss: 0.0531, Test Loss: 0.0275, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0423, Test Loss: 0.0049, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.0640, Test Loss: 0.0398, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.0816, Test Loss: 0.0643, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 2/5, Total Test Loss: 0.1764, Fold accuracy: 93.5653\n",
      "Fold 3/5:\n",
      "Epoch 1/10, Train Loss: 0.1334, Test Loss: 0.0052, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 2/10, Train Loss: 0.0997, Test Loss: 0.0092, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0737, Test Loss: 0.0252, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.1124, Test Loss: 0.2204, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.5928, Test Loss: 0.0529, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 6/10, Train Loss: 0.1229, Test Loss: 0.0732, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 7/10, Train Loss: 0.0847, Test Loss: 0.0294, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0837, Test Loss: 0.0772, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.1159, Test Loss: 0.1612, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.0565, Test Loss: 0.0194, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 3/5, Total Test Loss: 0.1958, Fold accuracy: 98.0589\n",
      "Fold 4/5:\n",
      "Epoch 1/10, Train Loss: 0.0189, Test Loss: 0.0045, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 2/10, Train Loss: 0.0693, Test Loss: 0.0005, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0730, Test Loss: 0.0036, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.0314, Test Loss: 0.0034, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0093, Test Loss: 0.0064, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 6/10, Train Loss: 0.0258, Test Loss: 0.0079, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 7/10, Train Loss: 0.0246, Test Loss: 0.0390, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0105, Test Loss: 0.0065, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.0235, Test Loss: 0.0004, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.0093, Test Loss: 0.0021, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 4/5, Total Test Loss: 0.1980, Fold accuracy: 99.7865\n",
      "Fold 5/5:\n",
      "Epoch 1/10, Train Loss: 0.0041, Test Loss: 0.0001, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 2/10, Train Loss: 0.0046, Test Loss: 0.0045, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 3/10, Train Loss: 0.0083, Test Loss: 0.0050, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 4/10, Train Loss: 0.0136, Test Loss: 0.0011, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 5/10, Train Loss: 0.0473, Test Loss: 0.0002, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 6/10, Train Loss: 0.0701, Test Loss: 0.0003, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 7/10, Train Loss: 0.0503, Test Loss: 0.0239, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 8/10, Train Loss: 0.0409, Test Loss: 0.0050, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 9/10, Train Loss: 0.0551, Test Loss: 0.1029, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Epoch 10/10, Train Loss: 0.1340, Test Loss: 0.0303, Total Time: 00 hours, 00 minutes, 16 seconds\n",
      "Fold 5/5, Total Test Loss: 0.2282, Fold accuracy: 96.9743\n",
      "avg_loss:  0.04564226750924367\n",
      "model_scored: 0.1531, avg_accuracy: 84.6948\n",
      "Finished gi4e_detected_eyes dataset with VGG\n",
      "----------------------\n",
      "Finished all datasets\n",
      "              dataset     model  avg_loss  avg_accuracy   total_time\n",
      "0           gi4e_full    ResNet  0.000005      0.000006  1256.201086\n",
      "1           gi4e_full  DenseNet  0.000087      0.000050   949.252779\n",
      "2           gi4e_full       VGG  0.053988      0.117809  1173.275935\n",
      "3       gi4e_raw_eyes    ResNet  0.197609      0.059315   573.807799\n",
      "4       gi4e_raw_eyes  DenseNet  0.014683      0.014551   787.467340\n",
      "5       gi4e_raw_eyes       VGG  0.193054      0.397976  1288.160237\n",
      "6  gi4e_detected_eyes    ResNet  0.001794      0.000420   846.130111\n",
      "7  gi4e_detected_eyes  DenseNet  0.114782      0.004473   787.358267\n",
      "8  gi4e_detected_eyes       VGG  0.045642      0.153052   925.128679\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(columns=['dataset', 'model', 'avg_loss', 'avg_accuracy', 'total_time'])\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "\tfor model in models:\n",
    "\t\tprint(f'Running {name} dataset with {model.__class__.__name__}')\n",
    "\t\t# do the train\n",
    "\t\tstart_time = time.time()\n",
    "\t\tscored, loss = doTheTrain(dataset, model)\n",
    "\t\tend_time = time.time()\n",
    "\t\ttotal_time = end_time - start_time\n",
    "\t\tprint(f'Finished {name} dataset with {model.__class__.__name__}')\n",
    "\t\tprint('----------------------')\n",
    "\n",
    "\t\t# save the result\n",
    "\t\tresult_df = pd.concat([result_df, pd.DataFrame({\n",
    "\t\t\t'model': [model.__class__.__name__],\n",
    "\t\t\t'dataset': [name],\n",
    "\t\t\t'avg_loss': [loss],\n",
    "\t\t\t'avg_accuracy': [scored],\n",
    "\t\t\t'total_time': [total_time]\n",
    "\t\t})], ignore_index=True)\n",
    "\n",
    "print('Finished all datasets')\n",
    "\n",
    "# print the result\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d796772",
   "metadata": {},
   "source": [
    "4. print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fca714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dataset     model  avg_loss  avg_accuracy  \\\n",
      "0           gi4e_full    ResNet  0.000005     99.999365   \n",
      "1           gi4e_full  DenseNet  0.000087     99.994973   \n",
      "2           gi4e_full       VGG  0.053988     88.219118   \n",
      "3       gi4e_raw_eyes    ResNet  0.197609     94.068484   \n",
      "4       gi4e_raw_eyes  DenseNet  0.014683     98.544904   \n",
      "5       gi4e_raw_eyes       VGG  0.193054     60.202415   \n",
      "6  gi4e_detected_eyes    ResNet  0.001794     99.958043   \n",
      "7  gi4e_detected_eyes  DenseNet  0.114782     99.552733   \n",
      "8  gi4e_detected_eyes       VGG  0.045642     84.694791   \n",
      "\n",
      "                 total_time  \n",
      "0 0 days 00:20:56.201085806  \n",
      "1 0 days 00:15:49.252779484  \n",
      "2 0 days 00:19:33.275934696  \n",
      "3 0 days 00:09:33.807798624  \n",
      "4 0 days 00:13:07.467339516  \n",
      "5 0 days 00:21:28.160236597  \n",
      "6 0 days 00:14:06.130110501  \n",
      "7 0 days 00:13:07.358267069  \n",
      "8 0 days 00:15:25.128678799  \n"
     ]
    }
   ],
   "source": [
    "# swap the first two columns\n",
    "result_df = result_df[['dataset', 'model', 'avg_loss', 'avg_accuracy', 'total_time']]\n",
    "# scale the avg_accuracy to 0-100\n",
    "result_df['avg_accuracy'] = 100 * (1 - result_df['avg_accuracy'])\n",
    "# display the total time in the format HH:MM:SS\n",
    "result_df['total_time'] = pd.to_timedelta(result_df['total_time'], unit='s')\n",
    "\n",
    "# save the result to csv\n",
    "result_df.to_csv(f'results_{time_str}.csv', index=False)\n",
    "# print the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d9c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dataset     model  avg_loss  avg_accuracy  \\\n",
      "0           gi4e_full    ResNet  0.000005     99.999365   \n",
      "1           gi4e_full  DenseNet  0.000087     99.994973   \n",
      "2           gi4e_full       VGG  0.053988     88.219118   \n",
      "3       gi4e_raw_eyes    ResNet  0.197609     94.068484   \n",
      "4       gi4e_raw_eyes  DenseNet  0.014683     98.544904   \n",
      "5       gi4e_raw_eyes       VGG  0.193054     60.202415   \n",
      "6  gi4e_detected_eyes    ResNet  0.001794     99.958043   \n",
      "7  gi4e_detected_eyes  DenseNet  0.114782     99.552733   \n",
      "8  gi4e_detected_eyes       VGG  0.045642     84.694791   \n",
      "\n",
      "                 total_time  \n",
      "0 0 days 00:20:56.201085806  \n",
      "1 0 days 00:15:49.252779484  \n",
      "2 0 days 00:19:33.275934696  \n",
      "3 0 days 00:09:33.807798624  \n",
      "4 0 days 00:13:07.467339516  \n",
      "5 0 days 00:21:28.160236597  \n",
      "6 0 days 00:14:06.130110501  \n",
      "7 0 days 00:13:07.358267069  \n",
      "8 0 days 00:15:25.128678799  \n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e46b4",
   "metadata": {},
   "source": [
    "# Embedded Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a6be8",
   "metadata": {},
   "source": [
    "- Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433d460f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResNet' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m embedded_models \u001b[38;5;241m=\u001b[39m [md\u001b[38;5;241m.\u001b[39mFeatureExtractor(model) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[1;32m----> 2\u001b[0m classifier_models \u001b[38;5;241m=\u001b[39m [md\u001b[38;5;241m.\u001b[39mClassifier(model) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m embedded_models \u001b[38;5;241m=\u001b[39m [md\u001b[38;5;241m.\u001b[39mFeatureExtractor(model) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[1;32m----> 2\u001b[0m classifier_models \u001b[38;5;241m=\u001b[39m [\u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n",
      "File \u001b[1;32md:\\Workspace\\thesis_sources\\model.py:31\u001b[0m, in \u001b[0;36mClassifier.__init__\u001b[1;34m(self, backbone)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28msuper\u001b[39m(Classifier, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# get the last layer from the backbone\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m \u001b[43mbackbone\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResNet' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "embedded_models = [md.FeatureExtractor(model) for model in models]\n",
    "classifier_models = [md.Classifier(model) for model in models]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c655b5fd",
   "metadata": {},
   "source": [
    "- Load the trained weight to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478d76c",
   "metadata": {},
   "source": [
    "- Transform the dataset to the embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa59dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting features for gi4e_full dataset with FeatureExtractor(VGG)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassifier model not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddedDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m classifier_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([classifier_df, pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: [classifier_model],\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: [model_dataset]\n\u001b[0;32m     20\u001b[0m })], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished getting features for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Workspace\\thesis_sources\\dataset.py:528\u001b[0m, in \u001b[0;36mEmbeddedDataset.__init__\u001b[1;34m(self, dataset, model)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Precompute embeddings for the entire dataset\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Workspace\\thesis_sources\\dataset.py:536\u001b[0m, in \u001b[0;36mEmbeddedDataset.compute_embeddings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    534\u001b[0m image, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[i]\n\u001b[0;32m    535\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mappend(embedding\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Workspace\\thesis_sources\\model.py:22\u001b[0m, in \u001b[0;36mFeatureExtractor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 22\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the output\u001b[39;00m\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "classifier_df = pd.DataFrame(columns=['key', 'dataset', 'model'])\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "  for model in embedded_models:\n",
    "    print(f'Getting features for {name} dataset with {model.__class__.__name__}')\n",
    "\n",
    "    # get the classifier model from the model\n",
    "    classifier_model = next((m for m in classifier_models if m.__class__.__name__ ==\n",
    "                            model.__class__.__name__.replace('FeatureExtractor', 'Classifier')), None)\n",
    "    if classifier_model is None:\n",
    "      print(f'Classifier model not found for {model.__class__.__name__}')\n",
    "      continue\n",
    "\n",
    "    model_dataset = ds.EmbeddedDataset(dataset, model)\n",
    "\n",
    "    classifier_df = pd.concat([classifier_df, pd.DataFrame({\n",
    "        'key': [f'{name}_{model.__class__.__name__}'],\n",
    "        'model': [classifier_model],\n",
    "        'dataset': [model_dataset]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    print(f'Finished getting features for {name} dataset with {model.__class__.__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0cc06",
   "metadata": {},
   "source": [
    "- Train all defined model on each registered datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21efd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gi4e_full dataset with Classifier\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# do the train\u001b[39;00m\n\u001b[0;32m      7\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 8\u001b[0m scored, loss \u001b[38;5;241m=\u001b[39m \u001b[43mdoTheTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     10\u001b[0m total_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36mdoTheTrain\u001b[1;34m(dataset, model)\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     12\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m86\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice: \u001b[39m\u001b[38;5;124m'\u001b[39m, trainer\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     16\u001b[0m avg_loss, metric \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcross_validate(train_ds, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[1;32md:\\Workspace\\thesis_sources\\train\\trainer.py:43\u001b[0m, in \u001b[0;36mClassifierTrainer.__init__\u001b[1;34m(self, model, optimizer, loss_fn, random_seed_value, device)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_seed_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m   \u001b[43mseed_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_seed_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Workspace\\thesis_sources\\train\\trainer.py:209\u001b[0m, in \u001b[0;36mseed_everything\u001b[1;34m(seed_value)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mseed_everything\u001b[39m(seed_value):\n\u001b[0;32m    208\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed_value)\n\u001b[1;32m--> 209\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m    212\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(seed_value)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\random.py:46\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\random.py:129\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    126\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m    127\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m--> 129\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:249\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 249\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[1;32mc:\\Users\\nnvuf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\random.py:127\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[0;32m    126\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m--> 127\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(columns=['dataset', 'model', 'avg_loss', 'avg_accuracy', 'total_time'])\n",
    "\n",
    "for index, row in classifier_df.iterrows():\n",
    "  dataset = row['dataset']\n",
    "  model = row['model']\n",
    "  key = row['key']\n",
    "\n",
    "  print(f'Running {key} dataset with {model.__class__.__name__}')\n",
    "  # do the train\n",
    "  start_time = time.time()\n",
    "  scored, loss = doTheTrain(dataset, model)\n",
    "  end_time = time.time()\n",
    "  total_time = end_time - start_time\n",
    "  print(f'Finished {key} dataset with {model.__class__.__name__}')\n",
    "  print('----------------------')\n",
    "\n",
    "  # save the result\n",
    "  result_df = pd.concat([result_df, pd.DataFrame({\n",
    "      'model': [model.__class__.__name__],\n",
    "      'dataset': [dataset.__class__.__name__],\n",
    "      'avg_loss': [loss],\n",
    "      'avg_accuracy': [scored],\n",
    "      'total_time': [total_time]\n",
    "  })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c5880",
   "metadata": {},
   "source": [
    "- Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbf0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the first two columns\n",
    "result_df = result_df[['dataset', 'model', 'avg_loss', 'avg_accuracy', 'total_time']]\n",
    "# scale the avg_accuracy to 0-100\n",
    "result_df['avg_accuracy'] = 100 * (1 - result_df['avg_accuracy'])\n",
    "# display the total time in the format HH:MM:SS\n",
    "result_df['total_time'] = pd.to_timedelta(result_df['total_time'], unit='s')\n",
    "\n",
    "# save the result to csv\n",
    "result_df.to_csv(f'results_{time_str}.csv', index=False)\n",
    "# print the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188561ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet\n",
      "Number of layers: 10\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "Model: DenseNet\n",
      "Number of layers: 2\n",
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n",
      "Model: VGG\n",
      "Number of layers: 3\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "\ttorchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT),\n",
    "  torchvision.models.densenet121(weights=torchvision.models.DenseNet121_Weights.DEFAULT),\n",
    "  torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "  # explore the model\n",
    "\tprint(f'Model: {model.__class__.__name__}')\n",
    "\t\n",
    "\t# explain the model\n",
    "\tprint(f'Number of layers: {len(list(model.children()))}')\n",
    "\tprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804849b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
